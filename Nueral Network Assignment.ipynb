{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting TensorFlow\n",
      "  Downloading tensorflow-2.5.0-cp38-cp38-win_amd64.whl (422.6 MB)\n",
      "Collecting h5py~=3.1.0\n",
      "  Downloading h5py-3.1.0-cp38-cp38-win_amd64.whl (2.7 MB)\n",
      "Collecting astunparse~=1.6.3\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting opt-einsum~=3.3.0\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Collecting tensorboard~=2.5\n",
      "  Downloading tensorboard-2.5.0-py3-none-any.whl (6.0 MB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.13.0-py3-none-any.whl (132 kB)\n",
      "Collecting keras-nightly~=2.5.0.dev\n",
      "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
      "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from TensorFlow) (3.15.6)\n",
      "Collecting google-pasta~=0.2\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Requirement already satisfied: typing-extensions~=3.7.4 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from TensorFlow) (3.7.4.3)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting grpcio~=1.34.0\n",
      "  Downloading grpcio-1.34.1-cp38-cp38-win_amd64.whl (2.9 MB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from TensorFlow) (0.35.1)\n",
      "Requirement already satisfied: six~=1.15.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from TensorFlow) (1.15.0)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting gast==0.4.0\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: numpy~=1.19.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from TensorFlow) (1.19.2)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Downloading google_auth_oauthlib-0.4.4-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->TensorFlow) (2.24.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->TensorFlow) (50.3.1.post20201107)\n",
      "Collecting tensorboard-plugin-wit>=1.6.0\n",
      "  Downloading tensorboard_plugin_wit-1.8.0-py3-none-any.whl (781 kB)\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading google_auth-1.32.0-py2.py3-none-any.whl (147 kB)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from tensorboard~=2.5->TensorFlow) (1.0.1)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.3.4-py3-none-any.whl (97 kB)\n",
      "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
      "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.0-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->TensorFlow) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->TensorFlow) (2020.6.20)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->TensorFlow) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->TensorFlow) (2.10)\n",
      "Collecting rsa<5,>=3.1.4; python_version >= \"3.6\"\n",
      "  Downloading rsa-4.7.2-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in c:\\users\\lenovo\\anaconda3\\lib\\site-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->TensorFlow) (4.2.1)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Downloading oauthlib-3.1.1-py2.py3-none-any.whl (146 kB)\n",
      "Collecting pyasn1>=0.1.3\n",
      "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
      "Building wheels for collected packages: wrapt, termcolor\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-py3-none-any.whl size=19558 sha256=f199480aafb128608c70a3913da2928755eff876944984213f9ac7d0020faf1b\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4835 sha256=5e318346b18acc54808f5bc870c271e02285932ab337ca49f4ece3b3b1d83c11\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "Successfully built wrapt termcolor\n",
      "Installing collected packages: h5py, astunparse, opt-einsum, pyasn1, rsa, pyasn1-modules, google-auth, oauthlib, requests-oauthlib, google-auth-oauthlib, tensorboard-plugin-wit, markdown, absl-py, grpcio, tensorboard-data-server, tensorboard, keras-nightly, wrapt, tensorflow-estimator, google-pasta, termcolor, flatbuffers, keras-preprocessing, gast, TensorFlow\n",
      "  Attempting uninstall: h5py\n",
      "    Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Attempting uninstall: wrapt\n",
      "    Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "Successfully installed TensorFlow-2.5.0 absl-py-0.13.0 astunparse-1.6.3 flatbuffers-1.12 gast-0.4.0 google-auth-1.32.0 google-auth-oauthlib-0.4.4 google-pasta-0.2.0 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 keras-preprocessing-1.1.2 markdown-3.3.4 oauthlib-3.1.1 opt-einsum-3.3.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-oauthlib-1.3.0 rsa-4.7.2 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.0 tensorflow-estimator-2.5.0 termcolor-1.1.0 wrapt-1.12.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0  ...         0   \n",
       "\n",
       "   monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0         0         0         0         1         0         0         0   \n",
       "1         0         0         0         0         0         0         1   \n",
       "2         0         0         0         0         0         0         1   \n",
       "3         0         0         0         1         0         0         0   \n",
       "4         0         0         0         1         0         0         0   \n",
       "\n",
       "   monthsep  size_category  \n",
       "0         0          small  \n",
       "1         0          small  \n",
       "2         0          small  \n",
       "3         0          small  \n",
       "4         0          small  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire=pd.read_csv(\"C://Users//Lenovo//Downloads//Assignment//Nueral Networks//forestfires.csv\")\n",
    "fire.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 517 entries, 0 to 516\n",
      "Data columns (total 31 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   month          517 non-null    object \n",
      " 1   day            517 non-null    object \n",
      " 2   FFMC           517 non-null    float64\n",
      " 3   DMC            517 non-null    float64\n",
      " 4   DC             517 non-null    float64\n",
      " 5   ISI            517 non-null    float64\n",
      " 6   temp           517 non-null    float64\n",
      " 7   RH             517 non-null    int64  \n",
      " 8   wind           517 non-null    float64\n",
      " 9   rain           517 non-null    float64\n",
      " 10  area           517 non-null    float64\n",
      " 11  dayfri         517 non-null    int64  \n",
      " 12  daymon         517 non-null    int64  \n",
      " 13  daysat         517 non-null    int64  \n",
      " 14  daysun         517 non-null    int64  \n",
      " 15  daythu         517 non-null    int64  \n",
      " 16  daytue         517 non-null    int64  \n",
      " 17  daywed         517 non-null    int64  \n",
      " 18  monthapr       517 non-null    int64  \n",
      " 19  monthaug       517 non-null    int64  \n",
      " 20  monthdec       517 non-null    int64  \n",
      " 21  monthfeb       517 non-null    int64  \n",
      " 22  monthjan       517 non-null    int64  \n",
      " 23  monthjul       517 non-null    int64  \n",
      " 24  monthjun       517 non-null    int64  \n",
      " 25  monthmar       517 non-null    int64  \n",
      " 26  monthmay       517 non-null    int64  \n",
      " 27  monthnov       517 non-null    int64  \n",
      " 28  monthoct       517 non-null    int64  \n",
      " 29  monthsep       517 non-null    int64  \n",
      " 30  size_category  517 non-null    object \n",
      "dtypes: float64(8), int64(20), object(3)\n",
      "memory usage: 125.3+ KB\n"
     ]
    }
   ],
   "source": [
    "fire.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>area</th>\n",
       "      <th>dayfri</th>\n",
       "      <th>...</th>\n",
       "      <th>monthdec</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "      <td>517.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>90.644681</td>\n",
       "      <td>110.872340</td>\n",
       "      <td>547.940039</td>\n",
       "      <td>9.021663</td>\n",
       "      <td>18.889168</td>\n",
       "      <td>44.288201</td>\n",
       "      <td>4.017602</td>\n",
       "      <td>0.021663</td>\n",
       "      <td>12.847292</td>\n",
       "      <td>0.164410</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017408</td>\n",
       "      <td>0.038685</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.061896</td>\n",
       "      <td>0.032882</td>\n",
       "      <td>0.104449</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.001934</td>\n",
       "      <td>0.029014</td>\n",
       "      <td>0.332689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.520111</td>\n",
       "      <td>64.046482</td>\n",
       "      <td>248.066192</td>\n",
       "      <td>4.559477</td>\n",
       "      <td>5.806625</td>\n",
       "      <td>16.317469</td>\n",
       "      <td>1.791653</td>\n",
       "      <td>0.295959</td>\n",
       "      <td>63.655818</td>\n",
       "      <td>0.371006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.130913</td>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.241199</td>\n",
       "      <td>0.178500</td>\n",
       "      <td>0.306138</td>\n",
       "      <td>0.062137</td>\n",
       "      <td>0.043980</td>\n",
       "      <td>0.168007</td>\n",
       "      <td>0.471632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>18.700000</td>\n",
       "      <td>1.100000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.200000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>90.200000</td>\n",
       "      <td>68.600000</td>\n",
       "      <td>437.700000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>15.500000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>2.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>91.600000</td>\n",
       "      <td>108.300000</td>\n",
       "      <td>664.200000</td>\n",
       "      <td>8.400000</td>\n",
       "      <td>19.300000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>92.900000</td>\n",
       "      <td>142.400000</td>\n",
       "      <td>713.900000</td>\n",
       "      <td>10.800000</td>\n",
       "      <td>22.800000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>4.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.570000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>96.200000</td>\n",
       "      <td>291.300000</td>\n",
       "      <td>860.600000</td>\n",
       "      <td>56.100000</td>\n",
       "      <td>33.300000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>6.400000</td>\n",
       "      <td>1090.840000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             FFMC         DMC          DC         ISI        temp          RH  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean    90.644681  110.872340  547.940039    9.021663   18.889168   44.288201   \n",
       "std      5.520111   64.046482  248.066192    4.559477    5.806625   16.317469   \n",
       "min     18.700000    1.100000    7.900000    0.000000    2.200000   15.000000   \n",
       "25%     90.200000   68.600000  437.700000    6.500000   15.500000   33.000000   \n",
       "50%     91.600000  108.300000  664.200000    8.400000   19.300000   42.000000   \n",
       "75%     92.900000  142.400000  713.900000   10.800000   22.800000   53.000000   \n",
       "max     96.200000  291.300000  860.600000   56.100000   33.300000  100.000000   \n",
       "\n",
       "             wind        rain         area      dayfri  ...    monthdec  \\\n",
       "count  517.000000  517.000000   517.000000  517.000000  ...  517.000000   \n",
       "mean     4.017602    0.021663    12.847292    0.164410  ...    0.017408   \n",
       "std      1.791653    0.295959    63.655818    0.371006  ...    0.130913   \n",
       "min      0.400000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "25%      2.700000    0.000000     0.000000    0.000000  ...    0.000000   \n",
       "50%      4.000000    0.000000     0.520000    0.000000  ...    0.000000   \n",
       "75%      4.900000    0.000000     6.570000    0.000000  ...    0.000000   \n",
       "max      9.400000    6.400000  1090.840000    1.000000  ...    1.000000   \n",
       "\n",
       "         monthfeb    monthjan    monthjul    monthjun    monthmar    monthmay  \\\n",
       "count  517.000000  517.000000  517.000000  517.000000  517.000000  517.000000   \n",
       "mean     0.038685    0.003868    0.061896    0.032882    0.104449    0.003868   \n",
       "std      0.193029    0.062137    0.241199    0.178500    0.306138    0.062137   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         monthnov    monthoct    monthsep  \n",
       "count  517.000000  517.000000  517.000000  \n",
       "mean     0.001934    0.029014    0.332689  \n",
       "std      0.043980    0.168007    0.471632  \n",
       "min      0.000000    0.000000    0.000000  \n",
       "25%      0.000000    0.000000    0.000000  \n",
       "50%      0.000000    0.000000    0.000000  \n",
       "75%      0.000000    0.000000    1.000000  \n",
       "max      1.000000    1.000000    1.000000  \n",
       "\n",
       "[8 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month            0\n",
       "day              0\n",
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire[fire.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>monthfeb</th>\n",
       "      <th>monthjan</th>\n",
       "      <th>monthjul</th>\n",
       "      <th>monthjun</th>\n",
       "      <th>monthmar</th>\n",
       "      <th>monthmay</th>\n",
       "      <th>monthnov</th>\n",
       "      <th>monthoct</th>\n",
       "      <th>monthsep</th>\n",
       "      <th>size_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oct</td>\n",
       "      <td>tue</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oct</td>\n",
       "      <td>sat</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mar</td>\n",
       "      <td>fri</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mar</td>\n",
       "      <td>sun</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>27.8</td>\n",
       "      <td>32</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.9</td>\n",
       "      <td>71</td>\n",
       "      <td>5.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>aug</td>\n",
       "      <td>sun</td>\n",
       "      <td>81.6</td>\n",
       "      <td>56.7</td>\n",
       "      <td>665.6</td>\n",
       "      <td>1.9</td>\n",
       "      <td>21.2</td>\n",
       "      <td>70</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>aug</td>\n",
       "      <td>sat</td>\n",
       "      <td>94.4</td>\n",
       "      <td>146.0</td>\n",
       "      <td>614.7</td>\n",
       "      <td>11.3</td>\n",
       "      <td>25.6</td>\n",
       "      <td>42</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>nov</td>\n",
       "      <td>tue</td>\n",
       "      <td>79.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>106.7</td>\n",
       "      <td>1.1</td>\n",
       "      <td>11.8</td>\n",
       "      <td>31</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>509 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    month  day  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  monthfeb  \\\n",
       "0     mar  fri  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...         0   \n",
       "1     oct  tue  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...         0   \n",
       "2     oct  sat  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...         0   \n",
       "3     mar  fri  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...         0   \n",
       "4     mar  sun  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...         0   \n",
       "..    ...  ...   ...    ...    ...   ...   ...  ..   ...   ...  ...       ...   \n",
       "512   aug  sun  81.6   56.7  665.6   1.9  27.8  32   2.7   0.0  ...         0   \n",
       "513   aug  sun  81.6   56.7  665.6   1.9  21.9  71   5.8   0.0  ...         0   \n",
       "514   aug  sun  81.6   56.7  665.6   1.9  21.2  70   6.7   0.0  ...         0   \n",
       "515   aug  sat  94.4  146.0  614.7  11.3  25.6  42   4.0   0.0  ...         0   \n",
       "516   nov  tue  79.5    3.0  106.7   1.1  11.8  31   4.5   0.0  ...         0   \n",
       "\n",
       "     monthjan  monthjul  monthjun  monthmar  monthmay  monthnov  monthoct  \\\n",
       "0           0         0         0         1         0         0         0   \n",
       "1           0         0         0         0         0         0         1   \n",
       "2           0         0         0         0         0         0         1   \n",
       "3           0         0         0         1         0         0         0   \n",
       "4           0         0         0         1         0         0         0   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "512         0         0         0         0         0         0         0   \n",
       "513         0         0         0         0         0         0         0   \n",
       "514         0         0         0         0         0         0         0   \n",
       "515         0         0         0         0         0         0         0   \n",
       "516         0         0         0         0         0         1         0   \n",
       "\n",
       "     monthsep  size_category  \n",
       "0           0          small  \n",
       "1           0          small  \n",
       "2           0          small  \n",
       "3           0          small  \n",
       "4           0          small  \n",
       "..        ...            ...  \n",
       "512         0          large  \n",
       "513         0          large  \n",
       "514         0          large  \n",
       "515         0          small  \n",
       "516         0          small  \n",
       "\n",
       "[509 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "month             object\n",
       "day               object\n",
       "FFMC             float64\n",
       "DMC              float64\n",
       "DC               float64\n",
       "ISI              float64\n",
       "temp             float64\n",
       "RH                 int64\n",
       "wind             float64\n",
       "rain             float64\n",
       "area             float64\n",
       "dayfri             int64\n",
       "daymon             int64\n",
       "daysat             int64\n",
       "daysun             int64\n",
       "daythu             int64\n",
       "daytue             int64\n",
       "daywed             int64\n",
       "monthapr           int64\n",
       "monthaug           int64\n",
       "monthdec           int64\n",
       "monthfeb           int64\n",
       "monthjan           int64\n",
       "monthjul           int64\n",
       "monthjun           int64\n",
       "monthmar           int64\n",
       "monthmay           int64\n",
       "monthnov           int64\n",
       "monthoct           int64\n",
       "monthsep           int64\n",
       "size_category     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fire.drop([\"month\",\"day\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "small    378\n",
       "large    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire[\"size_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFMC             0\n",
       "DMC              0\n",
       "DC               0\n",
       "ISI              0\n",
       "temp             0\n",
       "RH               0\n",
       "wind             0\n",
       "rain             0\n",
       "area             0\n",
       "dayfri           0\n",
       "daymon           0\n",
       "daysat           0\n",
       "daysun           0\n",
       "daythu           0\n",
       "daytue           0\n",
       "daywed           0\n",
       "monthapr         0\n",
       "monthaug         0\n",
       "monthdec         0\n",
       "monthfeb         0\n",
       "monthjan         0\n",
       "monthjul         0\n",
       "monthjun         0\n",
       "monthmar         0\n",
       "monthmay         0\n",
       "monthnov         0\n",
       "monthoct         0\n",
       "monthsep         0\n",
       "size_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    378\n",
       "1    139\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fire.loc[fire[\"size_category\"]=='small','size_category']=0\n",
    "fire.loc[fire[\"size_category\"]=='large','size_category']=1\n",
    "fire[\"size_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_func(i):\n",
    "     x = (i-i.min())/(i.max()-i.min())\n",
    "     return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data\n",
    "predictors = fire.iloc[:,0:28]\n",
    "target = fire.iloc[:,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "517"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors1 = norm_func(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data using train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(predictors1,target, test_size=0.3,stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the model\n",
    "model=keras.Sequential()\n",
    "def prep_model(hidden_dim):\n",
    "    model = Sequential()\n",
    "    for i in range(1,len(hidden_dim)-1):\n",
    "        if (i==1):\n",
    "            model.add(Dense(hidden_dim[i],input_dim=hidden_dim[0],activation=\"relu\"))\n",
    "        else:\n",
    "            model.add(Dense(hidden_dim[i],activation=\"relu\"))\n",
    "    model.add(Dense(hidden_dim[-1],kernel_initializer=\"normal\",activation=\"sigmoid\"))\n",
    "    model.compile(loss=\"binary_crossentropy\",optimizer = \"rmsprop\",metrics = [\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 17s 2ms/step - loss: 0.6843 - accuracy: 0.6500\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6519 - accuracy: 0.7257\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.7313\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5879 - accuracy: 0.7502\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5735 - accuracy: 0.7517\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5778 - accuracy: 0.7324\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5842 - accuracy: 0.7262\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7262\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5680 - accuracy: 0.7333\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5992 - accuracy: 0.7038\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7475\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6141 - accuracy: 0.6868\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5381 - accuracy: 0.7505\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7312\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7371\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7429\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7455\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5659 - accuracy: 0.7232\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7489\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5824 - accuracy: 0.7037\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7489\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.6033 - accuracy: 0.6939\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.7593\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7558\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7376\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7352\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7399\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.7611\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5692 - accuracy: 0.7228\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5126 - accuracy: 0.7685\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7528\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7589\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.7624\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.7583\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5681 - accuracy: 0.7149\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5140 - accuracy: 0.7578\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7572\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.7774\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.7702\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.7696\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5284 - accuracy: 0.7516\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7573\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.7602\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.7818\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.7597\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.7545\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.7716\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5108 - accuracy: 0.7811\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7745\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.7638\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.7681\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.7730\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.7686\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.7527\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4857 - accuracy: 0.7903\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.7531\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.7428\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4888 - accuracy: 0.7791\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7350\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7385\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.7899\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.7369\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.7608\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.7785\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.7781\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7824\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.7608\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7911\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.7741\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.8024\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5007 - accuracy: 0.7655\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4855 - accuracy: 0.7742\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5299 - accuracy: 0.7411\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.7683\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7706\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7660\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.7643\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4843 - accuracy: 0.7837\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.7600\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4903 - accuracy: 0.7714\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7833\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.7499\n",
      "Epoch 83/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8117\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.7472\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.7629\n",
      "Epoch 86/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7636\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5070 - accuracy: 0.7435\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5152 - accuracy: 0.7527\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5184 - accuracy: 0.7386\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.7518\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.7339\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4536 - accuracy: 0.7863\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4597 - accuracy: 0.7947\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7794\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5030 - accuracy: 0.7398\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4900 - accuracy: 0.7547\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.7651\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.7912\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.7819\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7696\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.7912\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.7717\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7821\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4934 - accuracy: 0.7616\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4506 - accuracy: 0.7980\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.7734\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4861 - accuracy: 0.7702\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7659\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7713\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5046 - accuracy: 0.7443\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.7602\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.7695\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.7776\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.7861\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4718 - accuracy: 0.7714\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7756\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4634 - accuracy: 0.7797\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.7610\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7776\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4881 - accuracy: 0.7688\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4316 - accuracy: 0.8037\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4612 - accuracy: 0.7924\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4562 - accuracy: 0.7868\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.7617\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.7412\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.7661\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.7715\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4798 - accuracy: 0.7454\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7873\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4966 - accuracy: 0.7704\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4488 - accuracy: 0.7996\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4525 - accuracy: 0.8017\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.7663\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7800\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4522 - accuracy: 0.7868\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.7644\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5239 - accuracy: 0.7597\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4449 - accuracy: 0.8031\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5122 - accuracy: 0.7209\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7720\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4884 - accuracy: 0.7657\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4345 - accuracy: 0.8083\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.8004\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4943 - accuracy: 0.7516\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4581 - accuracy: 0.7952\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4834 - accuracy: 0.7749\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.7691\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7698\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4664 - accuracy: 0.7952\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4580 - accuracy: 0.7824\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7758\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4614 - accuracy: 0.7804\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7908\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5061 - accuracy: 0.7536\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4680 - accuracy: 0.7786\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4560 - accuracy: 0.7732\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7692\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4568 - accuracy: 0.7975\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4630 - accuracy: 0.7731\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4723 - accuracy: 0.7638\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4476 - accuracy: 0.7965\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7834\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4591 - accuracy: 0.7908\n",
      "Epoch 164/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4486 - accuracy: 0.7834\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7905\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4781 - accuracy: 0.7658\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4547 - accuracy: 0.7585\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.4811 - accuracy: 0.7685\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.7780\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5078 - accuracy: 0.7560\n",
      "Epoch 171/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7732\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.7509\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4660 - accuracy: 0.7815\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4646 - accuracy: 0.7917\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.7834\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.7606\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4794 - accuracy: 0.7638\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7916\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.7539\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4578 - accuracy: 0.7700\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4435 - accuracy: 0.8147\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4770 - accuracy: 0.7671\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7501\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4930 - accuracy: 0.7666\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7764\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.7692\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.7562\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4361 - accuracy: 0.7955\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.7456\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.7514\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7651\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7843\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4651 - accuracy: 0.7706\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4876 - accuracy: 0.7600\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4737 - accuracy: 0.7704\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.7524\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5028 - accuracy: 0.7525\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7820\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4553 - accuracy: 0.7883\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.7850\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4613 - accuracy: 0.7756\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4543 - accuracy: 0.7880\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4768 - accuracy: 0.7564\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4456 - accuracy: 0.8006\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7749\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4527 - accuracy: 0.7852\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7797\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4803 - accuracy: 0.7422\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4689 - accuracy: 0.7754\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7656\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7510\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4520 - accuracy: 0.7853\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4873 - accuracy: 0.7744\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7669\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.7552\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4743 - accuracy: 0.7755\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.7926\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7380\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7876\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.7473\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.7524\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4665 - accuracy: 0.7670\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.7573\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4464 - accuracy: 0.7922\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4619 - accuracy: 0.7733\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.7695\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4583 - accuracy: 0.7795\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4703 - accuracy: 0.7737\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7589\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7639\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.7642\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4408 - accuracy: 0.8037\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4848 - accuracy: 0.7760\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4467 - accuracy: 0.7669\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4949 - accuracy: 0.7461\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4635 - accuracy: 0.7716\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4504 - accuracy: 0.7900\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7972\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7344\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4679 - accuracy: 0.7778\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4451 - accuracy: 0.7827\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.4759 - accuracy: 0.7548\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7807\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.4714 - accuracy: 0.7769\n",
      "Epoch 245/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7756\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4562 - accuracy: 0.7774\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4483 - accuracy: 0.7889\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4869 - accuracy: 0.7614\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4690 - accuracy: 0.7620\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.5180 - accuracy: 0.7411\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4620 - accuracy: 0.7846\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.3999 - accuracy: 0.8264\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7878\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4956 - accuracy: 0.7537\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7819\n",
      "Epoch 256/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4833 - accuracy: 0.7616\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.7682\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4923 - accuracy: 0.7661\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4470 - accuracy: 0.7832\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4864 - accuracy: 0.7714\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5069 - accuracy: 0.7380\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.7879\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4741 - accuracy: 0.7616\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.7631\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.7672\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.7499\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.7602\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4514 - accuracy: 0.7849\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.7533\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7699\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.7441\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7784\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7658\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4610 - accuracy: 0.7826\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4776 - accuracy: 0.7389\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.7600\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4893 - accuracy: 0.7593\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4577 - accuracy: 0.7686\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4971 - accuracy: 0.7590\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4980 - accuracy: 0.7400\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4508 - accuracy: 0.7821\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4995 - accuracy: 0.7482\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4877 - accuracy: 0.7601\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.4763 - accuracy: 0.7857\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.7996\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4908 - accuracy: 0.7520\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4442 - accuracy: 0.7839\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.7663\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4775 - accuracy: 0.7667\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 0.4664 - accuracy: 0.7797\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4588 - accuracy: 0.7700\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4394 - accuracy: 0.7924\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.7840\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4495 - accuracy: 0.7891\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4609 - accuracy: 0.7593\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4973 - accuracy: 0.7548\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.7822\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4889 - accuracy: 0.7635\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4453 - accuracy: 0.7943\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5118 - accuracy: 0.7215\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4944 - accuracy: 0.7513\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4766 - accuracy: 0.7786\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4551 - accuracy: 0.7759\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7617\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4820 - accuracy: 0.7601\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4615 - accuracy: 0.7789\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.7679\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7620\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7651\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4505 - accuracy: 0.7919\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7745\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4315 - accuracy: 0.7891\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4221 - accuracy: 0.8237\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4692 - accuracy: 0.7636\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4511 - accuracy: 0.7851\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5317 - accuracy: 0.7286\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.7715\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4835 - accuracy: 0.7663\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4572 - accuracy: 0.7860\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4747 - accuracy: 0.7648\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.7855\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4675 - accuracy: 0.7698\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7887\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4274 - accuracy: 0.8135\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7962\n",
      "Epoch 326/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7805\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.7900\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5045 - accuracy: 0.7481\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4654 - accuracy: 0.7673\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4961 - accuracy: 0.7457\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5058 - accuracy: 0.7465\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7636\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7567\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4592 - accuracy: 0.7797\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4482 - accuracy: 0.7786\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4645 - accuracy: 0.7730\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7986\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7553\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4595 - accuracy: 0.7730\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4399 - accuracy: 0.8038\n",
      "Epoch 341/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4496 - accuracy: 0.7747\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4715 - accuracy: 0.7697\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4851 - accuracy: 0.7357\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7807\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7686\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5050 - accuracy: 0.7547\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4661 - accuracy: 0.7776\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4783 - accuracy: 0.7605\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4447 - accuracy: 0.8104\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4744 - accuracy: 0.7662\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4715 - accuracy: 0.7558\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4875 - accuracy: 0.7589\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4593 - accuracy: 0.7588\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4669 - accuracy: 0.7679\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4704 - accuracy: 0.7610\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7805\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4515 - accuracy: 0.7975\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4598 - accuracy: 0.7843\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4772 - accuracy: 0.7523\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4678 - accuracy: 0.7665\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7681\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.7525\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4603 - accuracy: 0.7686\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.7571\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5043 - accuracy: 0.7409\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5076 - accuracy: 0.7328\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4365 - accuracy: 0.7975\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7534\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4382 - accuracy: 0.7836\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4655 - accuracy: 0.7756\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4432 - accuracy: 0.8084\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4823 - accuracy: 0.7308\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4830 - accuracy: 0.7642\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4536 - accuracy: 0.7774\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.7551\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4919 - accuracy: 0.7568\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4397 - accuracy: 0.7814\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4758 - accuracy: 0.7617\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4682 - accuracy: 0.7854\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.7499\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.7602\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4859 - accuracy: 0.7566\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4258 - accuracy: 0.7997\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4626 - accuracy: 0.7847\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4742 - accuracy: 0.7767\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4277 - accuracy: 0.7985\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7575\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4346 - accuracy: 0.7989\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4484 - accuracy: 0.7899\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4982 - accuracy: 0.7508\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4477 - accuracy: 0.7771\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4648 - accuracy: 0.7491\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.7764\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4780 - accuracy: 0.7598\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.7621\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4400 - accuracy: 0.7946\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4366 - accuracy: 0.7948\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4607 - accuracy: 0.7793\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4810 - accuracy: 0.7657\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4687 - accuracy: 0.7788\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7667\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4656 - accuracy: 0.7778\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.7669\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4757 - accuracy: 0.7740\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4580 - accuracy: 0.7846\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4827 - accuracy: 0.7610\n",
      "Epoch 407/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4751 - accuracy: 0.7655\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.7716\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4663 - accuracy: 0.7681\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4329 - accuracy: 0.8049\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.7491\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4926 - accuracy: 0.7458\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4479 - accuracy: 0.7953\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7796\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7912\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4872 - accuracy: 0.7541\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.5089 - accuracy: 0.7462\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.7736\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7886\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4962 - accuracy: 0.7493\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4238 - accuracy: 0.8002\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.7680\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4714 - accuracy: 0.7559\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7834\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4910 - accuracy: 0.7406\n",
      "Epoch 426/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.7770\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4433 - accuracy: 0.7833\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.7729\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4473 - accuracy: 0.7813\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.7496\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.7848\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.7492\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4433 - accuracy: 0.8011\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.7439\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7707\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4499 - accuracy: 0.7761\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4778 - accuracy: 0.7455\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.7679\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.7745\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7665\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4879 - accuracy: 0.7653\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4500 - accuracy: 0.8013\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4694 - accuracy: 0.7681\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4641 - accuracy: 0.7757\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4711 - accuracy: 0.7646\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.7535\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4413 - accuracy: 0.7895\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4785 - accuracy: 0.7574\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4816 - accuracy: 0.7636\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4487 - accuracy: 0.7864\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4855 - accuracy: 0.7676\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4489 - accuracy: 0.7748\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4748 - accuracy: 0.7743\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4115 - accuracy: 0.7977\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4732 - accuracy: 0.7674\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4350 - accuracy: 0.7957\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4845 - accuracy: 0.7514\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.7568\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4788 - accuracy: 0.7583\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4569 - accuracy: 0.7737\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4519 - accuracy: 0.7732\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.7651\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4527 - accuracy: 0.7818\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4662 - accuracy: 0.7576\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4584 - accuracy: 0.7805\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4730 - accuracy: 0.7592\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4594 - accuracy: 0.7963\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4565 - accuracy: 0.7633\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4853 - accuracy: 0.7480\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4686 - accuracy: 0.7515\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4534 - accuracy: 0.7776\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4313 - accuracy: 0.8000\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4448 - accuracy: 0.7888\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4624 - accuracy: 0.7465\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4931 - accuracy: 0.7569\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4498 - accuracy: 0.7904\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4699 - accuracy: 0.7471\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4668 - accuracy: 0.7703\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4438 - accuracy: 0.7845\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4531 - accuracy: 0.7811\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4282 - accuracy: 0.7920\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4541 - accuracy: 0.7856\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4566 - accuracy: 0.7902\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4445 - accuracy: 0.7688\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4401 - accuracy: 0.7928\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7682\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4366 - accuracy: 0.8018\n",
      "Epoch 488/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4551 - accuracy: 0.7862\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.7512\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.7755\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4814 - accuracy: 0.7734\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4616 - accuracy: 0.7808\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.7683\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4213 - accuracy: 0.8096\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4587 - accuracy: 0.7790\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7752\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4821 - accuracy: 0.7548\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4777 - accuracy: 0.7598\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4736 - accuracy: 0.7715\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.4450 - accuracy: 0.7841\n"
     ]
    }
   ],
   "source": [
    "first_model = prep_model([28,50,40,20,1])\n",
    "first_model.fit(np.asarray(x_train).astype(np.int),np.asarray(y_train).astype(np.int),epochs=500)\n",
    "pred_train = first_model.predict(np.array(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train = pd.Series([i[0] for i in pred_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [\"small\",\"large\"]\n",
    "pred_train_class = pd.Series([\"small\"]*361)\n",
    "pred_train_class[[i>0.5 for i in pred_train]]= \"large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    264\n",
       "1     97\n",
       "Name: size_category, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([x_train,y_train],axis=1)\n",
    "train[\"size_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7285318559556787"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For training data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "train[\"original_class\"] = \"small\"\n",
    "train.loc[train[\"size_category\"]==1,\"original_class\"] = \"large\"\n",
    "train.original_class.value_counts()\n",
    "confusion_matrix(pred_train_class,train[\"original_class\"])\n",
    "np.mean(pred_train_class==pd.Series(train[\"original_class\"]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original_class</th>\n",
       "      <th>large</th>\n",
       "      <th>small</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>large</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>93</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "original_class  large  small\n",
       "row_0                       \n",
       "large               4      5\n",
       "small              93    259"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(pred_train_class,pd.Series(train[\"original_class\"]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test = first_model.predict(x_test)\n",
    "pred_test = pd.Series([i[0] for i in pred_test])\n",
    "pred_test_class = pd.Series([\"small\"]*156)\n",
    "pred_test_class[[i>0.5 for i in pred_test]] = \"large\"\n",
    "test =pd.concat([x_test,y_test],axis=1)\n",
    "test[\"original_class\"]=\"small\"\n",
    "test.loc[test[\"size_category\"]==1,\"original_class\"] = \"large\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7115384615384616"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[\"original_class\"].value_counts()\n",
    "np.mean(pred_test_class==pd.Series(test[\"original_class\"]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>original_class</th>\n",
       "      <th>large</th>\n",
       "      <th>small</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>row_0</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>large</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>small</th>\n",
       "      <td>42</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "original_class  large  small\n",
       "row_0                       \n",
       "large               0      3\n",
       "small              42    111"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(pred_test_class,test[\"original_class\"])\n",
    "pd.crosstab(pred_test_class,pd.Series(test[\"original_class\"]).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_model(hidden_dim):\n",
    "    model = Sequential()\n",
    "    for i in range(1,len(hidden_dim)-1):\n",
    "        if (i==1):\n",
    "            model.add(Dense(hidden_dim[i],input_dim=hidden_dim[0],activation=\"relu\"))\n",
    "        else:\n",
    "            model.add(Dense(hidden_dim[i],activation=\"relu\"))\n",
    "    model.add(Dense(hidden_dim[-1],kernel_initializer=\"normal\",activation=\"linear\"))\n",
    "    model.compile(loss=\"mean_squared_error\",optimizer = \"adam\",metrics = [\"mse\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "12/12 [==============================] - 1s 1ms/step - loss: 0.2480 - mse: 0.2480\n",
      "Epoch 2/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1990 - mse: 0.1990\n",
      "Epoch 3/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2011 - mse: 0.2011\n",
      "Epoch 4/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2210 - mse: 0.2210\n",
      "Epoch 5/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1767 - mse: 0.1767\n",
      "Epoch 6/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1897 - mse: 0.1897\n",
      "Epoch 7/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.2021 - mse: 0.2021\n",
      "Epoch 8/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1848 - mse: 0.1848\n",
      "Epoch 9/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1865 - mse: 0.1865\n",
      "Epoch 10/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1837 - mse: 0.1837\n",
      "Epoch 11/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1782 - mse: 0.1782\n",
      "Epoch 12/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1815 - mse: 0.1815\n",
      "Epoch 13/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1723 - mse: 0.1723\n",
      "Epoch 14/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1593 - mse: 0.1593\n",
      "Epoch 15/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1761 - mse: 0.1761\n",
      "Epoch 16/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1818 - mse: 0.1818\n",
      "Epoch 17/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1812 - mse: 0.1812\n",
      "Epoch 18/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1807 - mse: 0.1807\n",
      "Epoch 19/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1830 - mse: 0.1830\n",
      "Epoch 20/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1610 - mse: 0.1610\n",
      "Epoch 21/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1580 - mse: 0.1580\n",
      "Epoch 22/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1700 - mse: 0.1700\n",
      "Epoch 23/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1733 - mse: 0.1733\n",
      "Epoch 24/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1612 - mse: 0.1612\n",
      "Epoch 25/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1798 - mse: 0.1798\n",
      "Epoch 26/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1709 - mse: 0.1709\n",
      "Epoch 27/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1560 - mse: 0.1560\n",
      "Epoch 28/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1749 - mse: 0.1749\n",
      "Epoch 29/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1749 - mse: 0.1749\n",
      "Epoch 30/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1772 - mse: 0.1772\n",
      "Epoch 31/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1541 - mse: 0.1541\n",
      "Epoch 32/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1518 - mse: 0.1518\n",
      "Epoch 33/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1521 - mse: 0.1521\n",
      "Epoch 34/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1584 - mse: 0.1584\n",
      "Epoch 35/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1618 - mse: 0.1618\n",
      "Epoch 36/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1563 - mse: 0.1563\n",
      "Epoch 37/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1611 - mse: 0.1611\n",
      "Epoch 38/500\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.1549 - mse: 0.154 - 0s 1ms/step - loss: 0.1545 - mse: 0.1545\n",
      "Epoch 39/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1551 - mse: 0.1551\n",
      "Epoch 40/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1666 - mse: 0.1666\n",
      "Epoch 41/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1519 - mse: 0.1519\n",
      "Epoch 42/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1628 - mse: 0.1628\n",
      "Epoch 43/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1606 - mse: 0.1606\n",
      "Epoch 44/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1498 - mse: 0.1498\n",
      "Epoch 45/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1600 - mse: 0.1600\n",
      "Epoch 46/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1576 - mse: 0.1576\n",
      "Epoch 47/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1581 - mse: 0.1581\n",
      "Epoch 48/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1522 - mse: 0.1522\n",
      "Epoch 49/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1626 - mse: 0.1626\n",
      "Epoch 50/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1590 - mse: 0.1590\n",
      "Epoch 51/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1676 - mse: 0.1676\n",
      "Epoch 52/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1681 - mse: 0.1681\n",
      "Epoch 53/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1534 - mse: 0.1534\n",
      "Epoch 54/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1503 - mse: 0.1503\n",
      "Epoch 55/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1559 - mse: 0.1559\n",
      "Epoch 56/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1615 - mse: 0.1615\n",
      "Epoch 57/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1609 - mse: 0.1609\n",
      "Epoch 58/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1581 - mse: 0.1581\n",
      "Epoch 59/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1642 - mse: 0.1642\n",
      "Epoch 60/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1646 - mse: 0.1646\n",
      "Epoch 61/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1708 - mse: 0.1708\n",
      "Epoch 62/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1511 - mse: 0.1511\n",
      "Epoch 63/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1605 - mse: 0.1605\n",
      "Epoch 64/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1587 - mse: 0.1587\n",
      "Epoch 65/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1478 - mse: 0.1478\n",
      "Epoch 66/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1551 - mse: 0.1551\n",
      "Epoch 67/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1660 - mse: 0.1660\n",
      "Epoch 68/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1610 - mse: 0.1610\n",
      "Epoch 69/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1566 - mse: 0.1566\n",
      "Epoch 70/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1535 - mse: 0.1535\n",
      "Epoch 71/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1571 - mse: 0.1571\n",
      "Epoch 72/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1525 - mse: 0.1525\n",
      "Epoch 73/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1614 - mse: 0.1614\n",
      "Epoch 74/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1561 - mse: 0.1561\n",
      "Epoch 75/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1501 - mse: 0.1501\n",
      "Epoch 76/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1501 - mse: 0.1501\n",
      "Epoch 77/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1447 - mse: 0.1447\n",
      "Epoch 78/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1535 - mse: 0.1535\n",
      "Epoch 79/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1577 - mse: 0.1577\n",
      "Epoch 80/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1522 - mse: 0.1522\n",
      "Epoch 81/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1646 - mse: 0.1646\n",
      "Epoch 82/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1608 - mse: 0.1608\n",
      "Epoch 83/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1632 - mse: 0.1632\n",
      "Epoch 84/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1534 - mse: 0.1534\n",
      "Epoch 85/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1532 - mse: 0.1532\n",
      "Epoch 86/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1542 - mse: 0.1542\n",
      "Epoch 87/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1479 - mse: 0.1479\n",
      "Epoch 88/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1568 - mse: 0.1568\n",
      "Epoch 89/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1486 - mse: 0.1486\n",
      "Epoch 90/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1430 - mse: 0.1430\n",
      "Epoch 91/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1620 - mse: 0.1620\n",
      "Epoch 92/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1491 - mse: 0.1491\n",
      "Epoch 93/500\n",
      "12/12 [==============================] - 0s 971us/step - loss: 0.1753 - mse: 0.1753\n",
      "Epoch 94/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1667 - mse: 0.1667\n",
      "Epoch 95/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1537 - mse: 0.1537\n",
      "Epoch 96/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1604 - mse: 0.1604\n",
      "Epoch 97/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1631 - mse: 0.1631\n",
      "Epoch 98/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1591 - mse: 0.1591\n",
      "Epoch 99/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1555 - mse: 0.1555\n",
      "Epoch 100/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1610 - mse: 0.1610\n",
      "Epoch 101/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1467 - mse: 0.1467\n",
      "Epoch 102/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1656 - mse: 0.1656\n",
      "Epoch 103/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1608 - mse: 0.1608\n",
      "Epoch 104/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1593 - mse: 0.1593\n",
      "Epoch 105/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1637 - mse: 0.1637\n",
      "Epoch 106/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1476 - mse: 0.1476\n",
      "Epoch 107/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1648 - mse: 0.1648\n",
      "Epoch 108/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1613 - mse: 0.1613\n",
      "Epoch 109/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1532 - mse: 0.1532\n",
      "Epoch 110/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1386 - mse: 0.1386\n",
      "Epoch 111/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1621 - mse: 0.1621\n",
      "Epoch 112/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1472 - mse: 0.1472\n",
      "Epoch 113/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1584 - mse: 0.1584\n",
      "Epoch 114/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1541 - mse: 0.1541\n",
      "Epoch 115/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1677 - mse: 0.1677\n",
      "Epoch 116/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1468 - mse: 0.1468\n",
      "Epoch 117/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1593 - mse: 0.1593\n",
      "Epoch 118/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1479 - mse: 0.1479\n",
      "Epoch 119/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1618 - mse: 0.1618\n",
      "Epoch 120/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1611 - mse: 0.1611\n",
      "Epoch 121/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1635 - mse: 0.1635\n",
      "Epoch 122/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1635 - mse: 0.1635\n",
      "Epoch 123/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1762 - mse: 0.1762\n",
      "Epoch 124/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1531 - mse: 0.1531\n",
      "Epoch 125/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1513 - mse: 0.1513\n",
      "Epoch 126/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1521 - mse: 0.1521\n",
      "Epoch 127/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1557 - mse: 0.1557\n",
      "Epoch 128/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1479 - mse: 0.1479\n",
      "Epoch 129/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1605 - mse: 0.1605\n",
      "Epoch 130/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1562 - mse: 0.1562\n",
      "Epoch 131/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1630 - mse: 0.1630\n",
      "Epoch 132/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1593 - mse: 0.1593\n",
      "Epoch 133/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1592 - mse: 0.1592\n",
      "Epoch 134/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1532 - mse: 0.1532\n",
      "Epoch 135/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1506 - mse: 0.1506\n",
      "Epoch 136/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1567 - mse: 0.1567\n",
      "Epoch 137/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1603 - mse: 0.1603\n",
      "Epoch 138/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1558 - mse: 0.1558\n",
      "Epoch 139/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1612 - mse: 0.1612\n",
      "Epoch 140/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1669 - mse: 0.1669\n",
      "Epoch 141/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1641 - mse: 0.1641\n",
      "Epoch 142/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1542 - mse: 0.1542\n",
      "Epoch 143/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1561 - mse: 0.1561\n",
      "Epoch 144/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1688 - mse: 0.1688\n",
      "Epoch 145/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1629 - mse: 0.1629\n",
      "Epoch 146/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1639 - mse: 0.1639\n",
      "Epoch 147/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1712 - mse: 0.1712\n",
      "Epoch 148/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1515 - mse: 0.1515\n",
      "Epoch 149/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1463 - mse: 0.1463\n",
      "Epoch 150/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1475 - mse: 0.1475\n",
      "Epoch 151/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1560 - mse: 0.1560\n",
      "Epoch 152/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1710 - mse: 0.1710\n",
      "Epoch 153/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1524 - mse: 0.1524\n",
      "Epoch 154/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1465 - mse: 0.1465\n",
      "Epoch 155/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1563 - mse: 0.1563\n",
      "Epoch 156/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1502 - mse: 0.1502\n",
      "Epoch 157/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1560 - mse: 0.1560\n",
      "Epoch 158/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1510 - mse: 0.1510\n",
      "Epoch 159/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1521 - mse: 0.1521\n",
      "Epoch 160/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1608 - mse: 0.1608\n",
      "Epoch 161/500\n",
      "12/12 [==============================] - 0s 999us/step - loss: 0.1579 - mse: 0.1579\n",
      "Epoch 162/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1608 - mse: 0.1608\n",
      "Epoch 163/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 0.1442 - mse: 0.1442\n",
      "Epoch 164/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1576 - mse: 0.1576\n",
      "Epoch 165/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1543 - mse: 0.1543\n",
      "Epoch 166/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1648 - mse: 0.1648\n",
      "Epoch 167/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1544 - mse: 0.1544\n",
      "Epoch 168/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1676 - mse: 0.1676\n",
      "Epoch 169/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1628 - mse: 0.1628\n",
      "Epoch 170/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1694 - mse: 0.1694\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1481 - mse: 0.1481\n",
      "Epoch 172/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1496 - mse: 0.1496\n",
      "Epoch 173/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1463 - mse: 0.1463\n",
      "Epoch 174/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1575 - mse: 0.1575\n",
      "Epoch 175/500\n",
      "12/12 [==============================] - 0s 994us/step - loss: 0.1582 - mse: 0.1582\n",
      "Epoch 176/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 0.1552 - mse: 0.1552\n",
      "Epoch 177/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1553 - mse: 0.1553\n",
      "Epoch 178/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1636 - mse: 0.1636\n",
      "Epoch 179/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1587 - mse: 0.1587\n",
      "Epoch 180/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1440 - mse: 0.1440\n",
      "Epoch 181/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1597 - mse: 0.1597\n",
      "Epoch 182/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1613 - mse: 0.1613\n",
      "Epoch 183/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1446 - mse: 0.1446\n",
      "Epoch 184/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1490 - mse: 0.1490\n",
      "Epoch 185/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1642 - mse: 0.1642\n",
      "Epoch 186/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1583 - mse: 0.1583\n",
      "Epoch 187/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1585 - mse: 0.1585\n",
      "Epoch 188/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1476 - mse: 0.1476\n",
      "Epoch 189/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1720 - mse: 0.1720\n",
      "Epoch 190/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1515 - mse: 0.1515\n",
      "Epoch 191/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1602 - mse: 0.1602\n",
      "Epoch 192/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1527 - mse: 0.1527\n",
      "Epoch 193/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1561 - mse: 0.1561\n",
      "Epoch 194/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1581 - mse: 0.1581\n",
      "Epoch 195/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1562 - mse: 0.1562\n",
      "Epoch 196/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1528 - mse: 0.1528\n",
      "Epoch 197/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1674 - mse: 0.1674\n",
      "Epoch 198/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1555 - mse: 0.1555\n",
      "Epoch 199/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1605 - mse: 0.1605\n",
      "Epoch 200/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1673 - mse: 0.1673\n",
      "Epoch 201/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1545 - mse: 0.1545\n",
      "Epoch 202/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1578 - mse: 0.1578\n",
      "Epoch 203/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1510 - mse: 0.1510\n",
      "Epoch 204/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1627 - mse: 0.1627\n",
      "Epoch 205/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1759 - mse: 0.1759\n",
      "Epoch 206/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1619 - mse: 0.1619\n",
      "Epoch 207/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1542 - mse: 0.1542\n",
      "Epoch 208/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1510 - mse: 0.1510\n",
      "Epoch 209/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1529 - mse: 0.1529\n",
      "Epoch 210/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1633 - mse: 0.1633\n",
      "Epoch 211/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1783 - mse: 0.1783\n",
      "Epoch 212/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1430 - mse: 0.1430\n",
      "Epoch 213/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1506 - mse: 0.1506\n",
      "Epoch 214/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1576 - mse: 0.1576\n",
      "Epoch 215/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1599 - mse: 0.1599\n",
      "Epoch 216/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1626 - mse: 0.1626\n",
      "Epoch 217/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1540 - mse: 0.1540\n",
      "Epoch 218/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1523 - mse: 0.1523\n",
      "Epoch 219/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1506 - mse: 0.1506\n",
      "Epoch 220/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1587 - mse: 0.1587\n",
      "Epoch 221/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1563 - mse: 0.1563\n",
      "Epoch 222/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1555 - mse: 0.1555\n",
      "Epoch 223/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1554 - mse: 0.1554\n",
      "Epoch 224/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1492 - mse: 0.1492\n",
      "Epoch 225/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1608 - mse: 0.1608\n",
      "Epoch 226/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1682 - mse: 0.1682\n",
      "Epoch 227/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1642 - mse: 0.1642\n",
      "Epoch 228/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1465 - mse: 0.1465\n",
      "Epoch 229/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1525 - mse: 0.1525\n",
      "Epoch 230/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1545 - mse: 0.1545\n",
      "Epoch 231/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1705 - mse: 0.1705\n",
      "Epoch 232/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1546 - mse: 0.1546\n",
      "Epoch 233/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1450 - mse: 0.1450\n",
      "Epoch 234/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1586 - mse: 0.1586\n",
      "Epoch 235/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1489 - mse: 0.1489\n",
      "Epoch 236/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1502 - mse: 0.1502\n",
      "Epoch 237/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1443 - mse: 0.1443\n",
      "Epoch 238/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1682 - mse: 0.1682\n",
      "Epoch 239/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1568 - mse: 0.1568\n",
      "Epoch 240/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1434 - mse: 0.1434\n",
      "Epoch 241/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1453 - mse: 0.1453\n",
      "Epoch 242/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1692 - mse: 0.1692\n",
      "Epoch 243/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1549 - mse: 0.1549\n",
      "Epoch 244/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1575 - mse: 0.1575\n",
      "Epoch 245/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1551 - mse: 0.1551\n",
      "Epoch 246/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1451 - mse: 0.1451\n",
      "Epoch 247/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1610 - mse: 0.1610\n",
      "Epoch 248/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1690 - mse: 0.1690\n",
      "Epoch 249/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1591 - mse: 0.1591\n",
      "Epoch 250/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1497 - mse: 0.1497\n",
      "Epoch 251/500\n",
      "12/12 [==============================] - 0s 999us/step - loss: 0.1705 - mse: 0.1705\n",
      "Epoch 252/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1439 - mse: 0.1439\n",
      "Epoch 253/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1678 - mse: 0.1678\n",
      "Epoch 254/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1518 - mse: 0.1518\n",
      "Epoch 255/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1527 - mse: 0.1527\n",
      "Epoch 256/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1489 - mse: 0.1489\n",
      "Epoch 257/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1529 - mse: 0.1529\n",
      "Epoch 258/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1523 - mse: 0.1523\n",
      "Epoch 259/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1720 - mse: 0.1720\n",
      "Epoch 260/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1421 - mse: 0.1421\n",
      "Epoch 261/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1450 - mse: 0.1450\n",
      "Epoch 262/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1585 - mse: 0.1585\n",
      "Epoch 263/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1474 - mse: 0.1474\n",
      "Epoch 264/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1549 - mse: 0.1549\n",
      "Epoch 265/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1587 - mse: 0.1587\n",
      "Epoch 266/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1601 - mse: 0.1601\n",
      "Epoch 267/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1535 - mse: 0.1535\n",
      "Epoch 268/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1780 - mse: 0.1780\n",
      "Epoch 269/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1546 - mse: 0.1546\n",
      "Epoch 270/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1542 - mse: 0.1542\n",
      "Epoch 271/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1562 - mse: 0.1562\n",
      "Epoch 272/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1539 - mse: 0.1539\n",
      "Epoch 273/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1424 - mse: 0.1424\n",
      "Epoch 274/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1501 - mse: 0.1501\n",
      "Epoch 275/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1623 - mse: 0.1623\n",
      "Epoch 276/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1504 - mse: 0.1504\n",
      "Epoch 277/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1488 - mse: 0.1488\n",
      "Epoch 278/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1607 - mse: 0.1607\n",
      "Epoch 279/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1475 - mse: 0.1475\n",
      "Epoch 280/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1742 - mse: 0.1742\n",
      "Epoch 281/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1382 - mse: 0.1382\n",
      "Epoch 282/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1554 - mse: 0.1554\n",
      "Epoch 283/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1522 - mse: 0.1522\n",
      "Epoch 284/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1536 - mse: 0.1536\n",
      "Epoch 285/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1702 - mse: 0.1702\n",
      "Epoch 286/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1511 - mse: 0.1511\n",
      "Epoch 287/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1470 - mse: 0.1470\n",
      "Epoch 288/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1740 - mse: 0.1740\n",
      "Epoch 289/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1575 - mse: 0.1575\n",
      "Epoch 290/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1515 - mse: 0.1515\n",
      "Epoch 291/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1572 - mse: 0.1572\n",
      "Epoch 292/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1550 - mse: 0.1550\n",
      "Epoch 293/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1553 - mse: 0.1553\n",
      "Epoch 294/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1486 - mse: 0.1486\n",
      "Epoch 295/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1582 - mse: 0.1582\n",
      "Epoch 296/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1527 - mse: 0.1527\n",
      "Epoch 297/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1513 - mse: 0.1513\n",
      "Epoch 298/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1524 - mse: 0.1524\n",
      "Epoch 299/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1618 - mse: 0.1618\n",
      "Epoch 300/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1635 - mse: 0.1635\n",
      "Epoch 301/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1561 - mse: 0.1561\n",
      "Epoch 302/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1552 - mse: 0.1552\n",
      "Epoch 303/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1518 - mse: 0.1518\n",
      "Epoch 304/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1526 - mse: 0.1526\n",
      "Epoch 305/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1489 - mse: 0.1489\n",
      "Epoch 306/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1694 - mse: 0.1694\n",
      "Epoch 307/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1582 - mse: 0.1582\n",
      "Epoch 308/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1516 - mse: 0.1516\n",
      "Epoch 309/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1648 - mse: 0.1648\n",
      "Epoch 310/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1574 - mse: 0.1574\n",
      "Epoch 311/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1696 - mse: 0.1696\n",
      "Epoch 312/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1587 - mse: 0.1587\n",
      "Epoch 313/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1503 - mse: 0.1503\n",
      "Epoch 314/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1572 - mse: 0.1572\n",
      "Epoch 315/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1501 - mse: 0.1501\n",
      "Epoch 316/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1638 - mse: 0.1638\n",
      "Epoch 317/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1611 - mse: 0.1611\n",
      "Epoch 318/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1431 - mse: 0.1431\n",
      "Epoch 319/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1597 - mse: 0.1597\n",
      "Epoch 320/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1722 - mse: 0.1722\n",
      "Epoch 321/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1572 - mse: 0.1572\n",
      "Epoch 322/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1674 - mse: 0.1674\n",
      "Epoch 323/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1592 - mse: 0.1592\n",
      "Epoch 324/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1538 - mse: 0.1538\n",
      "Epoch 325/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1517 - mse: 0.1517\n",
      "Epoch 326/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1549 - mse: 0.1549\n",
      "Epoch 327/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1513 - mse: 0.1513\n",
      "Epoch 328/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1607 - mse: 0.1607\n",
      "Epoch 329/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1605 - mse: 0.1605\n",
      "Epoch 330/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1437 - mse: 0.1437\n",
      "Epoch 331/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1756 - mse: 0.1756\n",
      "Epoch 332/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1543 - mse: 0.1543\n",
      "Epoch 333/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1508 - mse: 0.1508\n",
      "Epoch 334/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1675 - mse: 0.1675\n",
      "Epoch 335/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1690 - mse: 0.1690\n",
      "Epoch 336/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1466 - mse: 0.1466\n",
      "Epoch 337/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1551 - mse: 0.1551\n",
      "Epoch 338/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1457 - mse: 0.1457\n",
      "Epoch 339/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1557 - mse: 0.1557\n",
      "Epoch 340/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1675 - mse: 0.1675\n",
      "Epoch 341/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1525 - mse: 0.1525\n",
      "Epoch 342/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1605 - mse: 0.1605\n",
      "Epoch 343/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1659 - mse: 0.1659\n",
      "Epoch 344/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1619 - mse: 0.1619\n",
      "Epoch 345/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1521 - mse: 0.1521\n",
      "Epoch 346/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1620 - mse: 0.1620\n",
      "Epoch 347/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1399 - mse: 0.1399\n",
      "Epoch 348/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1507 - mse: 0.1507\n",
      "Epoch 349/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1666 - mse: 0.1666\n",
      "Epoch 350/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1433 - mse: 0.1433\n",
      "Epoch 351/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1484 - mse: 0.1484\n",
      "Epoch 352/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1356 - mse: 0.1356\n",
      "Epoch 353/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1506 - mse: 0.1506\n",
      "Epoch 354/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1495 - mse: 0.1495\n",
      "Epoch 355/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1562 - mse: 0.1562\n",
      "Epoch 356/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1566 - mse: 0.1566\n",
      "Epoch 357/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1481 - mse: 0.1481\n",
      "Epoch 358/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1552 - mse: 0.1552\n",
      "Epoch 359/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1547 - mse: 0.1547\n",
      "Epoch 360/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1578 - mse: 0.1578\n",
      "Epoch 361/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1477 - mse: 0.1477\n",
      "Epoch 362/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1611 - mse: 0.1611\n",
      "Epoch 363/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1521 - mse: 0.1521\n",
      "Epoch 364/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1455 - mse: 0.1455\n",
      "Epoch 365/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1662 - mse: 0.1662\n",
      "Epoch 366/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1524 - mse: 0.1524\n",
      "Epoch 367/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1552 - mse: 0.1552\n",
      "Epoch 368/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1626 - mse: 0.1626\n",
      "Epoch 369/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1459 - mse: 0.1459\n",
      "Epoch 370/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1678 - mse: 0.1678\n",
      "Epoch 371/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1569 - mse: 0.1569\n",
      "Epoch 372/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1438 - mse: 0.1438\n",
      "Epoch 373/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1552 - mse: 0.1552\n",
      "Epoch 374/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1616 - mse: 0.1616\n",
      "Epoch 375/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1591 - mse: 0.1591\n",
      "Epoch 376/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1384 - mse: 0.1384\n",
      "Epoch 377/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1527 - mse: 0.1527\n",
      "Epoch 378/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1558 - mse: 0.1558\n",
      "Epoch 379/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1650 - mse: 0.1650\n",
      "Epoch 380/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1498 - mse: 0.1498\n",
      "Epoch 381/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1515 - mse: 0.1515\n",
      "Epoch 382/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1492 - mse: 0.1492\n",
      "Epoch 383/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1644 - mse: 0.1644\n",
      "Epoch 384/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1584 - mse: 0.1584\n",
      "Epoch 385/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1486 - mse: 0.1486\n",
      "Epoch 386/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1686 - mse: 0.1686\n",
      "Epoch 387/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1480 - mse: 0.1480\n",
      "Epoch 388/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1541 - mse: 0.1541\n",
      "Epoch 389/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1462 - mse: 0.1462\n",
      "Epoch 390/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1575 - mse: 0.1575\n",
      "Epoch 391/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1496 - mse: 0.1496\n",
      "Epoch 392/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1535 - mse: 0.1535\n",
      "Epoch 393/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1524 - mse: 0.1524\n",
      "Epoch 394/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1562 - mse: 0.1562\n",
      "Epoch 395/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1564 - mse: 0.1564\n",
      "Epoch 396/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1427 - mse: 0.1427\n",
      "Epoch 397/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1512 - mse: 0.1512\n",
      "Epoch 398/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1608 - mse: 0.1608\n",
      "Epoch 399/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1544 - mse: 0.1544\n",
      "Epoch 400/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1407 - mse: 0.1407\n",
      "Epoch 401/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1587 - mse: 0.1587\n",
      "Epoch 402/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1514 - mse: 0.1514\n",
      "Epoch 403/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1379 - mse: 0.1379\n",
      "Epoch 404/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1564 - mse: 0.1564\n",
      "Epoch 405/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1563 - mse: 0.1563\n",
      "Epoch 406/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1669 - mse: 0.1669\n",
      "Epoch 407/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1506 - mse: 0.1506\n",
      "Epoch 408/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1621 - mse: 0.1621\n",
      "Epoch 409/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1569 - mse: 0.1569\n",
      "Epoch 410/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1527 - mse: 0.1527\n",
      "Epoch 411/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1561 - mse: 0.1561\n",
      "Epoch 412/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1549 - mse: 0.1549\n",
      "Epoch 413/500\n",
      "12/12 [==============================] - 0s 999us/step - loss: 0.1593 - mse: 0.1593\n",
      "Epoch 414/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1607 - mse: 0.1607\n",
      "Epoch 415/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1570 - mse: 0.1570\n",
      "Epoch 416/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1441 - mse: 0.1441\n",
      "Epoch 417/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1626 - mse: 0.1626\n",
      "Epoch 418/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1510 - mse: 0.1510\n",
      "Epoch 419/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1539 - mse: 0.1539\n",
      "Epoch 420/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1598 - mse: 0.1598\n",
      "Epoch 421/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1491 - mse: 0.1491\n",
      "Epoch 422/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1623 - mse: 0.1623\n",
      "Epoch 423/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1496 - mse: 0.1496\n",
      "Epoch 424/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1469 - mse: 0.1469\n",
      "Epoch 425/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1641 - mse: 0.1641\n",
      "Epoch 426/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1636 - mse: 0.1636\n",
      "Epoch 427/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1466 - mse: 0.1466\n",
      "Epoch 428/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1614 - mse: 0.1614\n",
      "Epoch 429/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1591 - mse: 0.1591\n",
      "Epoch 430/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1587 - mse: 0.1587\n",
      "Epoch 431/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1574 - mse: 0.1574\n",
      "Epoch 432/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1545 - mse: 0.1545\n",
      "Epoch 433/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1477 - mse: 0.1477\n",
      "Epoch 434/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1592 - mse: 0.1592\n",
      "Epoch 435/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1620 - mse: 0.1620\n",
      "Epoch 436/500\n",
      "12/12 [==============================] - 0s 999us/step - loss: 0.1487 - mse: 0.1487\n",
      "Epoch 437/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1515 - mse: 0.1515\n",
      "Epoch 438/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1536 - mse: 0.1536\n",
      "Epoch 439/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1560 - mse: 0.1560\n",
      "Epoch 440/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1613 - mse: 0.1613\n",
      "Epoch 441/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1504 - mse: 0.1504\n",
      "Epoch 442/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1528 - mse: 0.1528\n",
      "Epoch 443/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1528 - mse: 0.1528\n",
      "Epoch 444/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1558 - mse: 0.1558\n",
      "Epoch 445/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1641 - mse: 0.1641\n",
      "Epoch 446/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1588 - mse: 0.1588\n",
      "Epoch 447/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1411 - mse: 0.1411\n",
      "Epoch 448/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1444 - mse: 0.1444\n",
      "Epoch 449/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1483 - mse: 0.1483\n",
      "Epoch 450/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1696 - mse: 0.1696\n",
      "Epoch 451/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1680 - mse: 0.1680\n",
      "Epoch 452/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1577 - mse: 0.1577\n",
      "Epoch 453/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1666 - mse: 0.1666\n",
      "Epoch 454/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1584 - mse: 0.1584\n",
      "Epoch 455/500\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1427 - mse: 0.1427\n",
      "Epoch 456/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1521 - mse: 0.1521\n",
      "Epoch 457/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1678 - mse: 0.1678\n",
      "Epoch 458/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1655 - mse: 0.1655\n",
      "Epoch 459/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1468 - mse: 0.1468\n",
      "Epoch 460/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1519 - mse: 0.1519\n",
      "Epoch 461/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1631 - mse: 0.1631\n",
      "Epoch 462/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1536 - mse: 0.1536\n",
      "Epoch 463/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1478 - mse: 0.1478\n",
      "Epoch 464/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 0.1582 - mse: 0.1582\n",
      "Epoch 465/500\n",
      "12/12 [==============================] - 0s 909us/step - loss: 0.1584 - mse: 0.1584\n",
      "Epoch 466/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1710 - mse: 0.1710\n",
      "Epoch 467/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1639 - mse: 0.1639\n",
      "Epoch 468/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1557 - mse: 0.1557\n",
      "Epoch 469/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1540 - mse: 0.1540\n",
      "Epoch 470/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1638 - mse: 0.1638\n",
      "Epoch 471/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1498 - mse: 0.1498\n",
      "Epoch 472/500\n",
      "12/12 [==============================] - 0s 999us/step - loss: 0.1529 - mse: 0.1529\n",
      "Epoch 473/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1507 - mse: 0.1507\n",
      "Epoch 474/500\n",
      "12/12 [==============================] - 0s 999us/step - loss: 0.1390 - mse: 0.1390\n",
      "Epoch 475/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1749 - mse: 0.1749\n",
      "Epoch 476/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1557 - mse: 0.1557\n",
      "Epoch 477/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1593 - mse: 0.1593\n",
      "Epoch 478/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1610 - mse: 0.1610\n",
      "Epoch 479/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1499 - mse: 0.1499\n",
      "Epoch 480/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1505 - mse: 0.1505\n",
      "Epoch 481/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1503 - mse: 0.1503\n",
      "Epoch 482/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1588 - mse: 0.1588\n",
      "Epoch 483/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1598 - mse: 0.1598\n",
      "Epoch 484/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1612 - mse: 0.1612\n",
      "Epoch 485/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1546 - mse: 0.1546\n",
      "Epoch 486/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1490 - mse: 0.1490\n",
      "Epoch 487/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1589 - mse: 0.1589\n",
      "Epoch 488/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1657 - mse: 0.1657\n",
      "Epoch 489/500\n",
      "12/12 [==============================] - 0s 1000us/step - loss: 0.1442 - mse: 0.1442\n",
      "Epoch 490/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1598 - mse: 0.1598\n",
      "Epoch 491/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1622 - mse: 0.1622\n",
      "Epoch 492/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1515 - mse: 0.1515\n",
      "Epoch 493/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1553 - mse: 0.1553\n",
      "Epoch 494/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1516 - mse: 0.1516\n",
      "Epoch 495/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1643 - mse: 0.1643\n",
      "Epoch 496/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1560 - mse: 0.1560\n",
      "Epoch 497/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1504 - mse: 0.1504\n",
      "Epoch 498/500\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.1553 - mse: 0.1553\n",
      "Epoch 499/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1546 - mse: 0.1546\n",
      "Epoch 500/500\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.1496 - mse: 0.1496\n"
     ]
    }
   ],
   "source": [
    "first_model = prep_model([28,50,40,20,1])\n",
    "first_model.fit(np.asarray(x_train).astype(np.int),np.asarray(y_train).astype(np.int),epochs=500)\n",
    "pred_train = first_model.predict(np.array(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.asarray(x_train).astype(np.int)\n",
    "\n",
    "y_train=np.asarray(y_train).astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "25/25 [==============================] - 2s 17ms/step - loss: 3.8739 - accuracy: 0.0054 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5754 - accuracy: 0.0040 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4300 - accuracy: 4.7944e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6945 - accuracy: 0.0110 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/150\n",
      "25/25 [==============================] - 0s 910us/step - loss: 3.7605 - accuracy: 0.0054 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/150\n",
      "25/25 [==============================] - 0s 923us/step - loss: 3.5020 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5473 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8224 - accuracy: 6.4666e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7158 - accuracy: 0.0026 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4936 - accuracy: 0.0014 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6033 - accuracy: 8.2149e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7062 - accuracy: 0.0049 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6480 - accuracy: 0.0018 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/150\n",
      "25/25 [==============================] - 0s 886us/step - loss: 3.8011 - accuracy: 0.0148 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8087 - accuracy: 0.0012 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/150\n",
      "25/25 [==============================] - 0s 915us/step - loss: 3.5397 - accuracy: 0.0018 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6832 - accuracy: 0.0029 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.7804 - accuracy: 4.7944e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6320 - accuracy: 0.0029 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/150\n",
      "25/25 [==============================] - 0s 997us/step - loss: 3.8181 - accuracy: 8.2149e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/150\n",
      "25/25 [==============================] - 0s 944us/step - loss: 3.7270 - accuracy: 0.0148 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5208 - accuracy: 0.0068 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8073 - accuracy: 0.0021 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8249 - accuracy: 0.0014 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8337 - accuracy: 0.0032 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6337 - accuracy: 0.0044 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.7334 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5580 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.2398 - accuracy: 0.0010 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/150\n",
      "25/25 [==============================] - 0s 850us/step - loss: 3.7099 - accuracy: 0.0040 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5943 - accuracy: 0.0078 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6956 - accuracy: 0.0018 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7080 - accuracy: 0.0078 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.9963 - accuracy: 0.0010 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8880 - accuracy: 0.0148 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6992 - accuracy: 0.0054 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.0620 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/150\n",
      "25/25 [==============================] - 0s 863us/step - loss: 3.8538 - accuracy: 0.0032 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8660 - accuracy: 0.0078 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.0077 - accuracy: 6.4666e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.9909 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/150\n",
      "25/25 [==============================] - 0s 783us/step - loss: 3.7133 - accuracy: 0.0032 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/150\n",
      "25/25 [==============================] - 0s 863us/step - loss: 3.5854 - accuracy: 0.0036 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6354 - accuracy: 0.0018 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9911 - accuracy: 0.0021 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5668 - accuracy: 8.2149e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5720 - accuracy: 0.0036 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/150\n",
      "25/25 [==============================] - 0s 911us/step - loss: 3.7627 - accuracy: 0.0021 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9853 - accuracy: 0.0029 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/150\n",
      "25/25 [==============================] - 0s 894us/step - loss: 3.8325 - accuracy: 0.0054 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7839 - accuracy: 0.0044 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8315 - accuracy: 0.0023 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8468 - accuracy: 0.0148 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0367 - accuracy: 0.0032 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0779 - accuracy: 0.0021 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7986 - accuracy: 0.0068 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9449 - accuracy: 0.0049 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1471 - accuracy: 0.0040 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5642 - accuracy: 6.4666e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0912 - accuracy: 0.0148 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3832 - accuracy: 6.4666e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7146 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7691 - accuracy: 0.0021 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.2921 - accuracy: 0.0110 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6736 - accuracy: 0.0054 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9048 - accuracy: 0.0068 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8467 - accuracy: 0.0054 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6730 - accuracy: 0.0078 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3994 - accuracy: 6.4666e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1969 - accuracy: 0.0036 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7863 - accuracy: 0.0012 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5638 - accuracy: 0.0078 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5098 - accuracy: 0.0054 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5664 - accuracy: 0.0010 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.7360 - accuracy: 0.0110 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.0823 - accuracy: 0.0012 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8923 - accuracy: 0.0012 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.9786 - accuracy: 0.0029 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.0625 - accuracy: 0.0091 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6996 - accuracy: 0.0021 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.1897 - accuracy: 0.0110 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.4859 - accuracy: 3.1918e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.4395 - accuracy: 8.2149e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.1733 - accuracy: 0.0010 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5132 - accuracy: 0.0091 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5703 - accuracy: 0.0110 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.4857 - accuracy: 0.0078 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.4868 - accuracy: 0.0049 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6832 - accuracy: 0.0078 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5192 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.4886 - accuracy: 0.0018 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8208 - accuracy: 6.4666e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7368 - accuracy: 0.0091 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8331 - accuracy: 0.0078 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6255 - accuracy: 0.0012 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5886 - accuracy: 0.0044 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.4305 - accuracy: 0.0029 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8942 - accuracy: 0.0014 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4044 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8947 - accuracy: 0.0044 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7296 - accuracy: 0.0036 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4869 - accuracy: 0.0016 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8964 - accuracy: 0.0010 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.5099 - accuracy: 0.0026 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3240 - accuracy: 4.7944e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.0848 - accuracy: 0.0014 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9690 - accuracy: 0.0078 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4486 - accuracy: 0.0148 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6865 - accuracy: 4.7944e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5206 - accuracy: 0.0049 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.3685 - accuracy: 0.0032 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.7896 - accuracy: 0.0018 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8437 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.7921 - accuracy: 0.0018 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.4905 - accuracy: 0.0148 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7649 - accuracy: 0.0036 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0809 - accuracy: 6.4666e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.7035 - accuracy: 6.4666e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.9232 - accuracy: 0.0010 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.9296 - accuracy: 0.0021 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.2356 - accuracy: 0.0010 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5851 - accuracy: 0.0068 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.2207 - accuracy: 0.0026 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6276 - accuracy: 0.0014 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8516 - accuracy: 0.0068 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.9495 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6112 - accuracy: 0.0026 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.3578 - accuracy: 0.0012 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6606 - accuracy: 0.0040 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.1770 - accuracy: 0.0010 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8788 - accuracy: 8.2149e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.5702 - accuracy: 4.7944e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6507 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8569 - accuracy: 0.0040 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8671 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8518 - accuracy: 8.2149e-04 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.6319 - accuracy: 0.0049 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8294 - accuracy: 0.0110 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.8898 - accuracy: 0.0040 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.0609 - accuracy: 0.0010 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.4043 - accuracy: 0.0049 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/150\n",
      "25/25 [==============================] - 0s 969us/step - loss: 4.0273 - accuracy: 0.0110 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.8156 - accuracy: 0.0049 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 4.0628 - accuracy: 0.0044 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.7153 - accuracy: 0.0032 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6857 - accuracy: 0.0040 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/150\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 3.6594 - accuracy: 0.0014 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 3.4487 - accuracy: 0.0012 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/150\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 4.1476 - accuracy: 0.0018 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/150\n",
      "25/25 [==============================] - 0s 928us/step - loss: 3.6700 - accuracy: 0.0061 - val_loss: 3.8078 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist=model.fit(np.array(x_train),np.array(y_train), validation_split=0.33, epochs=150, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 3.7627 - accuracy: 0.0028\n",
      "accuracy: 0.28%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_train,y_train)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gas Turbines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas = pd.read_csv(\"C://Users//Lenovo//Downloads//Assignment//Nueral Networks//gas_turbines.csv\")\n",
    "gas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15039 entries, 0 to 15038\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   AT      15039 non-null  float64\n",
      " 1   AP      15039 non-null  float64\n",
      " 2   AH      15039 non-null  float64\n",
      " 3   AFDP    15039 non-null  float64\n",
      " 4   GTEP    15039 non-null  float64\n",
      " 5   TIT     15039 non-null  float64\n",
      " 6   TAT     15039 non-null  float64\n",
      " 7   TEY     15039 non-null  float64\n",
      " 8   CDP     15039 non-null  float64\n",
      " 9   CO      15039 non-null  float64\n",
      " 10  NOX     15039 non-null  float64\n",
      "dtypes: float64(11)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "gas.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.00000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "      <td>15039.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>17.764381</td>\n",
       "      <td>1013.19924</td>\n",
       "      <td>79.124174</td>\n",
       "      <td>4.200294</td>\n",
       "      <td>25.419061</td>\n",
       "      <td>1083.798770</td>\n",
       "      <td>545.396183</td>\n",
       "      <td>134.188464</td>\n",
       "      <td>12.102353</td>\n",
       "      <td>1.972499</td>\n",
       "      <td>68.190934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.574323</td>\n",
       "      <td>6.41076</td>\n",
       "      <td>13.793439</td>\n",
       "      <td>0.760197</td>\n",
       "      <td>4.173916</td>\n",
       "      <td>16.527806</td>\n",
       "      <td>7.866803</td>\n",
       "      <td>15.829717</td>\n",
       "      <td>1.103196</td>\n",
       "      <td>2.222206</td>\n",
       "      <td>10.470586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.522300</td>\n",
       "      <td>985.85000</td>\n",
       "      <td>30.344000</td>\n",
       "      <td>2.087400</td>\n",
       "      <td>17.878000</td>\n",
       "      <td>1000.800000</td>\n",
       "      <td>512.450000</td>\n",
       "      <td>100.170000</td>\n",
       "      <td>9.904400</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>27.765000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.408000</td>\n",
       "      <td>1008.90000</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>3.723900</td>\n",
       "      <td>23.294000</td>\n",
       "      <td>1079.600000</td>\n",
       "      <td>542.170000</td>\n",
       "      <td>127.985000</td>\n",
       "      <td>11.622000</td>\n",
       "      <td>0.858055</td>\n",
       "      <td>61.303500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.186000</td>\n",
       "      <td>1012.80000</td>\n",
       "      <td>82.266000</td>\n",
       "      <td>4.186200</td>\n",
       "      <td>25.082000</td>\n",
       "      <td>1088.700000</td>\n",
       "      <td>549.890000</td>\n",
       "      <td>133.780000</td>\n",
       "      <td>12.025000</td>\n",
       "      <td>1.390200</td>\n",
       "      <td>66.601000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>23.862500</td>\n",
       "      <td>1016.90000</td>\n",
       "      <td>90.043500</td>\n",
       "      <td>4.550900</td>\n",
       "      <td>27.184000</td>\n",
       "      <td>1096.000000</td>\n",
       "      <td>550.060000</td>\n",
       "      <td>140.895000</td>\n",
       "      <td>12.578000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>73.935500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>34.929000</td>\n",
       "      <td>1034.20000</td>\n",
       "      <td>100.200000</td>\n",
       "      <td>7.610600</td>\n",
       "      <td>37.402000</td>\n",
       "      <td>1100.800000</td>\n",
       "      <td>550.610000</td>\n",
       "      <td>174.610000</td>\n",
       "      <td>15.081000</td>\n",
       "      <td>44.103000</td>\n",
       "      <td>119.890000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 AT           AP            AH          AFDP          GTEP  \\\n",
       "count  15039.000000  15039.00000  15039.000000  15039.000000  15039.000000   \n",
       "mean      17.764381   1013.19924     79.124174      4.200294     25.419061   \n",
       "std        7.574323      6.41076     13.793439      0.760197      4.173916   \n",
       "min        0.522300    985.85000     30.344000      2.087400     17.878000   \n",
       "25%       11.408000   1008.90000     69.750000      3.723900     23.294000   \n",
       "50%       18.186000   1012.80000     82.266000      4.186200     25.082000   \n",
       "75%       23.862500   1016.90000     90.043500      4.550900     27.184000   \n",
       "max       34.929000   1034.20000    100.200000      7.610600     37.402000   \n",
       "\n",
       "                TIT           TAT           TEY           CDP            CO  \\\n",
       "count  15039.000000  15039.000000  15039.000000  15039.000000  15039.000000   \n",
       "mean    1083.798770    545.396183    134.188464     12.102353      1.972499   \n",
       "std       16.527806      7.866803     15.829717      1.103196      2.222206   \n",
       "min     1000.800000    512.450000    100.170000      9.904400      0.000388   \n",
       "25%     1079.600000    542.170000    127.985000     11.622000      0.858055   \n",
       "50%     1088.700000    549.890000    133.780000     12.025000      1.390200   \n",
       "75%     1096.000000    550.060000    140.895000     12.578000      2.160400   \n",
       "max     1100.800000    550.610000    174.610000     15.081000     44.103000   \n",
       "\n",
       "                NOX  \n",
       "count  15039.000000  \n",
       "mean      68.190934  \n",
       "std       10.470586  \n",
       "min       27.765000  \n",
       "25%       61.303500  \n",
       "50%       66.601000  \n",
       "75%       73.935500  \n",
       "max      119.890000  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.412953</td>\n",
       "      <td>-0.549432</td>\n",
       "      <td>-0.099333</td>\n",
       "      <td>-0.049103</td>\n",
       "      <td>0.093067</td>\n",
       "      <td>0.338569</td>\n",
       "      <td>-0.207495</td>\n",
       "      <td>-0.100705</td>\n",
       "      <td>-0.088588</td>\n",
       "      <td>-0.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>-0.412953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042573</td>\n",
       "      <td>0.040318</td>\n",
       "      <td>0.078575</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>-0.223479</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>0.131198</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.256744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>-0.549432</td>\n",
       "      <td>0.042573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.119249</td>\n",
       "      <td>-0.202784</td>\n",
       "      <td>-0.247781</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>-0.110272</td>\n",
       "      <td>-0.182010</td>\n",
       "      <td>0.165505</td>\n",
       "      <td>0.143061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFDP</th>\n",
       "      <td>-0.099333</td>\n",
       "      <td>0.040318</td>\n",
       "      <td>-0.119249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744251</td>\n",
       "      <td>0.627254</td>\n",
       "      <td>-0.571541</td>\n",
       "      <td>0.717995</td>\n",
       "      <td>0.727152</td>\n",
       "      <td>-0.334207</td>\n",
       "      <td>-0.037299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEP</th>\n",
       "      <td>-0.049103</td>\n",
       "      <td>0.078575</td>\n",
       "      <td>-0.202784</td>\n",
       "      <td>0.744251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874526</td>\n",
       "      <td>-0.756884</td>\n",
       "      <td>0.977042</td>\n",
       "      <td>0.993784</td>\n",
       "      <td>-0.508259</td>\n",
       "      <td>-0.208496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIT</th>\n",
       "      <td>0.093067</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>-0.247781</td>\n",
       "      <td>0.627254</td>\n",
       "      <td>0.874526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.357320</td>\n",
       "      <td>0.891587</td>\n",
       "      <td>0.887238</td>\n",
       "      <td>-0.688272</td>\n",
       "      <td>-0.231636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAT</th>\n",
       "      <td>0.338569</td>\n",
       "      <td>-0.223479</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>-0.571541</td>\n",
       "      <td>-0.756884</td>\n",
       "      <td>-0.357320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.720356</td>\n",
       "      <td>-0.744740</td>\n",
       "      <td>0.063404</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEY</th>\n",
       "      <td>-0.207495</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>-0.110272</td>\n",
       "      <td>0.717995</td>\n",
       "      <td>0.977042</td>\n",
       "      <td>0.891587</td>\n",
       "      <td>-0.720356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>-0.541751</td>\n",
       "      <td>-0.102631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDP</th>\n",
       "      <td>-0.100705</td>\n",
       "      <td>0.131198</td>\n",
       "      <td>-0.182010</td>\n",
       "      <td>0.727152</td>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.887238</td>\n",
       "      <td>-0.744740</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.520783</td>\n",
       "      <td>-0.169103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>-0.088588</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.165505</td>\n",
       "      <td>-0.334207</td>\n",
       "      <td>-0.508259</td>\n",
       "      <td>-0.688272</td>\n",
       "      <td>0.063404</td>\n",
       "      <td>-0.541751</td>\n",
       "      <td>-0.520783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.600006</td>\n",
       "      <td>0.256744</td>\n",
       "      <td>0.143061</td>\n",
       "      <td>-0.037299</td>\n",
       "      <td>-0.208496</td>\n",
       "      <td>-0.231636</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>-0.102631</td>\n",
       "      <td>-0.169103</td>\n",
       "      <td>0.316743</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
       "AT    1.000000 -0.412953 -0.549432 -0.099333 -0.049103  0.093067  0.338569   \n",
       "AP   -0.412953  1.000000  0.042573  0.040318  0.078575  0.029650 -0.223479   \n",
       "AH   -0.549432  0.042573  1.000000 -0.119249 -0.202784 -0.247781  0.010859   \n",
       "AFDP -0.099333  0.040318 -0.119249  1.000000  0.744251  0.627254 -0.571541   \n",
       "GTEP -0.049103  0.078575 -0.202784  0.744251  1.000000  0.874526 -0.756884   \n",
       "TIT   0.093067  0.029650 -0.247781  0.627254  0.874526  1.000000 -0.357320   \n",
       "TAT   0.338569 -0.223479  0.010859 -0.571541 -0.756884 -0.357320  1.000000   \n",
       "TEY  -0.207495  0.146939 -0.110272  0.717995  0.977042  0.891587 -0.720356   \n",
       "CDP  -0.100705  0.131198 -0.182010  0.727152  0.993784  0.887238 -0.744740   \n",
       "CO   -0.088588  0.041614  0.165505 -0.334207 -0.508259 -0.688272  0.063404   \n",
       "NOX  -0.600006  0.256744  0.143061 -0.037299 -0.208496 -0.231636  0.009888   \n",
       "\n",
       "           TEY       CDP        CO       NOX  \n",
       "AT   -0.207495 -0.100705 -0.088588 -0.600006  \n",
       "AP    0.146939  0.131198  0.041614  0.256744  \n",
       "AH   -0.110272 -0.182010  0.165505  0.143061  \n",
       "AFDP  0.717995  0.727152 -0.334207 -0.037299  \n",
       "GTEP  0.977042  0.993784 -0.508259 -0.208496  \n",
       "TIT   0.891587  0.887238 -0.688272 -0.231636  \n",
       "TAT  -0.720356 -0.744740  0.063404  0.009888  \n",
       "TEY   1.000000  0.988473 -0.541751 -0.102631  \n",
       "CDP   0.988473  1.000000 -0.520783 -0.169103  \n",
       "CO   -0.541751 -0.520783  1.000000  0.316743  \n",
       "NOX  -0.102631 -0.169103  0.316743  1.000000  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 11)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas[gas.duplicated()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "550.01    270\n",
       "550.00    268\n",
       "550.04    266\n",
       "550.03    253\n",
       "549.98    252\n",
       "         ... \n",
       "545.08      1\n",
       "541.12      1\n",
       "541.55      1\n",
       "545.20      1\n",
       "528.00      1\n",
       "Name: TAT, Length: 2340, dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gas['TAT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "def calc_vif(X):\n",
    "\n",
    "    # Calculating VIF\n",
    "    vif = pd.DataFrame()\n",
    "    vif[\"variables\"] = X.columns\n",
    "    vif[\"VIF\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "\n",
    "    return(vif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variables</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AT</td>\n",
       "      <td>3.414439e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AP</td>\n",
       "      <td>1.842147e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AH</td>\n",
       "      <td>6.863745e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AFDP</td>\n",
       "      <td>8.580114e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GTEP</td>\n",
       "      <td>1.233878e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>TIT</td>\n",
       "      <td>1.372092e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>TAT</td>\n",
       "      <td>8.166382e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CDP</td>\n",
       "      <td>3.858125e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>CO</td>\n",
       "      <td>3.813210e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NOX</td>\n",
       "      <td>1.071006e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  variables           VIF\n",
       "0        AT  3.414439e+01\n",
       "1        AP  1.842147e+04\n",
       "2        AH  6.863745e+01\n",
       "3      AFDP  8.580114e+01\n",
       "4      GTEP  1.233878e+04\n",
       "5       TIT  1.372092e+06\n",
       "6       TAT  8.166382e+05\n",
       "7       CDP  3.858125e+04\n",
       "8        CO  3.813210e+00\n",
       "9       NOX  1.071006e+02"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = gas.drop('TEY',axis=1)\n",
    "calc_vif(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_func(i):\n",
    "     x = (i-i.min())/(i.max()-i.min())\n",
    "     return (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = gas.drop('TEY',axis=1)\n",
    "target = gas['TEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15039"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15039"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 10)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors.shape #shape of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039,)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target.shape  #shape of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.184182</td>\n",
       "      <td>0.456050</td>\n",
       "      <td>0.951314</td>\n",
       "      <td>0.255758</td>\n",
       "      <td>0.091426</td>\n",
       "      <td>0.584</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.135340</td>\n",
       "      <td>0.071522</td>\n",
       "      <td>0.596548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.182020</td>\n",
       "      <td>0.466391</td>\n",
       "      <td>0.955881</td>\n",
       "      <td>0.255721</td>\n",
       "      <td>0.094755</td>\n",
       "      <td>0.585</td>\n",
       "      <td>0.984015</td>\n",
       "      <td>0.133988</td>\n",
       "      <td>0.073372</td>\n",
       "      <td>0.597134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.185295</td>\n",
       "      <td>0.474664</td>\n",
       "      <td>0.939003</td>\n",
       "      <td>0.252571</td>\n",
       "      <td>0.097367</td>\n",
       "      <td>0.586</td>\n",
       "      <td>0.980608</td>\n",
       "      <td>0.134567</td>\n",
       "      <td>0.072576</td>\n",
       "      <td>0.593791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.189922</td>\n",
       "      <td>0.482937</td>\n",
       "      <td>0.929126</td>\n",
       "      <td>0.252227</td>\n",
       "      <td>0.098033</td>\n",
       "      <td>0.588</td>\n",
       "      <td>0.983753</td>\n",
       "      <td>0.135533</td>\n",
       "      <td>0.072375</td>\n",
       "      <td>0.595984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.199830</td>\n",
       "      <td>0.493278</td>\n",
       "      <td>0.927708</td>\n",
       "      <td>0.255323</td>\n",
       "      <td>0.096650</td>\n",
       "      <td>0.589</td>\n",
       "      <td>0.983491</td>\n",
       "      <td>0.136692</td>\n",
       "      <td>0.073647</td>\n",
       "      <td>0.592087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>0.247272</td>\n",
       "      <td>0.408480</td>\n",
       "      <td>0.975092</td>\n",
       "      <td>0.263380</td>\n",
       "      <td>0.065868</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.884696</td>\n",
       "      <td>0.095739</td>\n",
       "      <td>0.102448</td>\n",
       "      <td>0.562214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>0.214075</td>\n",
       "      <td>0.414685</td>\n",
       "      <td>0.984153</td>\n",
       "      <td>0.256826</td>\n",
       "      <td>0.078672</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.806342</td>\n",
       "      <td>0.102113</td>\n",
       "      <td>0.109894</td>\n",
       "      <td>0.566100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>0.195962</td>\n",
       "      <td>0.422958</td>\n",
       "      <td>0.989922</td>\n",
       "      <td>0.251593</td>\n",
       "      <td>0.084614</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.651730</td>\n",
       "      <td>0.111772</td>\n",
       "      <td>0.180552</td>\n",
       "      <td>0.685449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>0.188443</td>\n",
       "      <td>0.433299</td>\n",
       "      <td>0.982936</td>\n",
       "      <td>0.246451</td>\n",
       "      <td>0.076777</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.754455</td>\n",
       "      <td>0.121431</td>\n",
       "      <td>0.141693</td>\n",
       "      <td>0.710578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>0.186173</td>\n",
       "      <td>0.441572</td>\n",
       "      <td>0.961821</td>\n",
       "      <td>0.242631</td>\n",
       "      <td>0.073141</td>\n",
       "      <td>0.491</td>\n",
       "      <td>0.875262</td>\n",
       "      <td>0.131090</td>\n",
       "      <td>0.112946</td>\n",
       "      <td>0.702665</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             AT        AP        AH      AFDP      GTEP    TIT       TAT  \\\n",
       "0      0.184182  0.456050  0.951314  0.255758  0.091426  0.584  0.984015   \n",
       "1      0.182020  0.466391  0.955881  0.255721  0.094755  0.585  0.984015   \n",
       "2      0.185295  0.474664  0.939003  0.252571  0.097367  0.586  0.980608   \n",
       "3      0.189922  0.482937  0.929126  0.252227  0.098033  0.588  0.983753   \n",
       "4      0.199830  0.493278  0.927708  0.255323  0.096650  0.589  0.983491   \n",
       "...         ...       ...       ...       ...       ...    ...       ...   \n",
       "15034  0.247272  0.408480  0.975092  0.263380  0.065868  0.489  0.884696   \n",
       "15035  0.214075  0.414685  0.984153  0.256826  0.078672  0.455  0.806342   \n",
       "15036  0.195962  0.422958  0.989922  0.251593  0.084614  0.369  0.651730   \n",
       "15037  0.188443  0.433299  0.982936  0.246451  0.076777  0.424  0.754455   \n",
       "15038  0.186173  0.441572  0.961821  0.242631  0.073141  0.491  0.875262   \n",
       "\n",
       "            CDP        CO       NOX  \n",
       "0      0.135340  0.071522  0.596548  \n",
       "1      0.133988  0.073372  0.597134  \n",
       "2      0.134567  0.072576  0.593791  \n",
       "3      0.135533  0.072375  0.595984  \n",
       "4      0.136692  0.073647  0.592087  \n",
       "...         ...       ...       ...  \n",
       "15034  0.095739  0.102448  0.562214  \n",
       "15035  0.102113  0.109894  0.566100  \n",
       "15036  0.111772  0.180552  0.685449  \n",
       "15037  0.121431  0.141693  0.710578  \n",
       "15038  0.131090  0.112946  0.702665  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictors1 = norm_func(predictors)\n",
    "predictors1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test= train_test_split(predictors1,target, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(12, activation='relu', input_shape=(10,)),\n",
    "    Dense(8, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "878/878 [==============================] - 2s 1ms/step - loss: 2068.4432 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "878/878 [==============================] - 1s 966us/step - loss: 2068.0518 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "878/878 [==============================] - 1s 968us/step - loss: 2069.1645 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "878/878 [==============================] - 1s 963us/step - loss: 2068.2282 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2069.1752 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2069.0448 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2068.9818 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2072.6285 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2064.3933 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "878/878 [==============================] - 1s 966us/step - loss: 2068.0023 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2065.7664 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2068.9803 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2068.8576 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2073.2754 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "878/878 [==============================] - 1s 921us/step - loss: 2070.4126 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "878/878 [==============================] - 1s 943us/step - loss: 2069.3280 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "878/878 [==============================] - 1s 992us/step - loss: 2070.4376 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "878/878 [==============================] - 1s 942us/step - loss: 2072.9113 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "878/878 [==============================] - 1s 973us/step - loss: 2064.8687 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "878/878 [==============================] - 1s 947us/step - loss: 2066.5871 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "878/878 [==============================] - 1s 994us/step - loss: 2069.5716 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "878/878 [==============================] - 1s 962us/step - loss: 2064.5431 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "878/878 [==============================] - 1s 901us/step - loss: 2069.8079 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2072.5826 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2071.5865 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2066.4496 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2064.3165 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2067.8158 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "878/878 [==============================] - 1s 953us/step - loss: 2068.2507 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "878/878 [==============================] - 1s 996us/step - loss: 2068.7559 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2066.7416 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "878/878 [==============================] - 1s 988us/step - loss: 2070.1097 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2066.8497 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2070.7349 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2073.1794 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "878/878 [==============================] - 1s 995us/step - loss: 2068.2941 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2068.5983 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2069.0914 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "878/878 [==============================] - 1s 982us/step - loss: 2069.7641 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "878/878 [==============================] - 1s 996us/step - loss: 2067.2399 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "878/878 [==============================] - 1s 987us/step - loss: 2068.2834 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "878/878 [==============================] - 1s 996us/step - loss: 2066.9783 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "878/878 [==============================] - 1s 993us/step - loss: 2067.5280 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2069.5190 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "878/878 [==============================] - 1s 989us/step - loss: 2068.3283 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "878/878 [==============================] - 1s 968us/step - loss: 2067.1920 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "878/878 [==============================] - 1s 978us/step - loss: 2067.4762 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "878/878 [==============================] - 1s 980us/step - loss: 2068.6192 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "878/878 [==============================] - 1s 994us/step - loss: 2069.7584 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "878/878 [==============================] - 1s 970us/step - loss: 2065.7719 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "878/878 [==============================] - 1s 986us/step - loss: 2068.8752 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878/878 [==============================] - 1s 960us/step - loss: 2070.9603 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "878/878 [==============================] - 1s 957us/step - loss: 2068.5780 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "878/878 [==============================] - 1s 961us/step - loss: 2066.0302 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "878/878 [==============================] - 1s 982us/step - loss: 2073.1013 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "878/878 [==============================] - 1s 974us/step - loss: 2069.0243 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "878/878 [==============================] - 1s 957us/step - loss: 2071.5708 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "878/878 [==============================] - 1s 979us/step - loss: 2066.3931 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "878/878 [==============================] - 1s 956us/step - loss: 2067.7328 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "878/878 [==============================] - 1s 969us/step - loss: 2069.8144 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "878/878 [==============================] - 1s 954us/step - loss: 2071.6413 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "878/878 [==============================] - 1s 977us/step - loss: 2065.4643 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2069.1959 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2068.6907 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2064.1819 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2066.5979 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "878/878 [==============================] - 1s 993us/step - loss: 2072.0599 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "878/878 [==============================] - 1s 939us/step - loss: 2066.7438 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "878/878 [==============================] - 1s 964us/step - loss: 2071.2558 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "878/878 [==============================] - 1s 949us/step - loss: 2068.5405 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "878/878 [==============================] - 1s 965us/step - loss: 2074.6659 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "878/878 [==============================] - 1s 948us/step - loss: 2066.1423 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "878/878 [==============================] - 1s 956us/step - loss: 2068.6497 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "878/878 [==============================] - 1s 955us/step - loss: 2065.4449 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "878/878 [==============================] - 1s 958us/step - loss: 2069.0024 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "878/878 [==============================] - 1s 966us/step - loss: 2067.4788 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "878/878 [==============================] - 1s 963us/step - loss: 2068.7887 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "878/878 [==============================] - 1s 945us/step - loss: 2068.4005 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "878/878 [==============================] - 1s 962us/step - loss: 2067.3744 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "878/878 [==============================] - 1s 958us/step - loss: 2067.9516 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "878/878 [==============================] - 1s 962us/step - loss: 2068.3218 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "878/878 [==============================] - 1s 950us/step - loss: 2064.9973 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "878/878 [==============================] - 1s 975us/step - loss: 2067.7209 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "878/878 [==============================] - 1s 979us/step - loss: 2067.2888 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "878/878 [==============================] - 1s 948us/step - loss: 2067.1520 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "878/878 [==============================] - 1s 958us/step - loss: 2063.3754 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "878/878 [==============================] - 1s 961us/step - loss: 2068.9697 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "878/878 [==============================] - 1s 952us/step - loss: 2066.8836 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "878/878 [==============================] - 1s 969us/step - loss: 2066.5536 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "878/878 [==============================] - 1s 963us/step - loss: 2068.3150 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "878/878 [==============================] - 1s 942us/step - loss: 2065.5733 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "878/878 [==============================] - 1s 983us/step - loss: 2067.0756 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "878/878 [==============================] - 1s 971us/step - loss: 2068.8693 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "878/878 [==============================] - 1s 952us/step - loss: 2068.4677 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "878/878 [==============================] - 1s 987us/step - loss: 2071.1180 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "878/878 [==============================] - 1s 984us/step - loss: 2071.1738 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "878/878 [==============================] - 1s 949us/step - loss: 2068.6187 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "878/878 [==============================] - 1s 971us/step - loss: 2068.9857 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "878/878 [==============================] - 1s 995us/step - loss: 2071.2119 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "878/878 [==============================] - 1s 989us/step - loss: 2067.6316 - accuracy: 0.0000e+00 - val_loss: 2073.6960 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(np.array(x_train),np.array(y_train),\n",
    "          batch_size=12, epochs=100,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 2073.6960 - accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Sequential([\n",
    "    Dense(16, activation='relu', input_shape=(10,)),\n",
    "    Dense(12, activation='relu'),\n",
    "    Dense(1, activation='linear'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',\n",
    "              metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "878/878 [==============================] - 2s 1ms/step - loss: 12001.3807 - mse: 12001.3806 - val_loss: 88.8549 - val_mse: 88.8549\n",
      "Epoch 2/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 74.5113 - mse: 74.5113 - val_loss: 47.7224 - val_mse: 47.7224\n",
      "Epoch 3/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 40.2232 - mse: 40.2232 - val_loss: 30.2822 - val_mse: 30.2822\n",
      "Epoch 4/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 27.8021 - mse: 27.8021 - val_loss: 25.6194 - val_mse: 25.6194\n",
      "Epoch 5/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 23.6827 - mse: 23.6827 - val_loss: 22.5082 - val_mse: 22.5082\n",
      "Epoch 6/100\n",
      "878/878 [==============================] - 1s 947us/step - loss: 21.6627 - mse: 21.6627 - val_loss: 20.6282 - val_mse: 20.6282\n",
      "Epoch 7/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 19.1554 - mse: 19.1554 - val_loss: 17.2272 - val_mse: 17.2272\n",
      "Epoch 8/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 16.8266 - mse: 16.8266 - val_loss: 14.5590 - val_mse: 14.5590\n",
      "Epoch 9/100\n",
      "878/878 [==============================] - 1s 949us/step - loss: 14.3567 - mse: 14.3567 - val_loss: 12.2673 - val_mse: 12.2673\n",
      "Epoch 10/100\n",
      "878/878 [==============================] - 1s 902us/step - loss: 11.7918 - mse: 11.7918 - val_loss: 10.5159 - val_mse: 10.5159\n",
      "Epoch 11/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 9.8091 - mse: 9.8091 - val_loss: 8.1009 - val_mse: 8.1009\n",
      "Epoch 12/100\n",
      "878/878 [==============================] - 1s 940us/step - loss: 7.9502 - mse: 7.9502 - val_loss: 6.3746 - val_mse: 6.3746\n",
      "Epoch 13/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 6.0030 - mse: 6.0030 - val_loss: 4.7709 - val_mse: 4.7709\n",
      "Epoch 14/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 4.5737 - mse: 4.5737 - val_loss: 3.4491 - val_mse: 3.4491\n",
      "Epoch 15/100\n",
      "878/878 [==============================] - 1s 997us/step - loss: 3.2495 - mse: 3.2495 - val_loss: 2.2622 - val_mse: 2.2622\n",
      "Epoch 16/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 2.1773 - mse: 2.1773 - val_loss: 1.5041 - val_mse: 1.5041\n",
      "Epoch 17/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 1.4780 - mse: 1.4780 - val_loss: 1.0673 - val_mse: 1.0673\n",
      "Epoch 18/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 1.1023 - mse: 1.1023 - val_loss: 0.8551 - val_mse: 0.8551\n",
      "Epoch 19/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.9114 - mse: 0.9114 - val_loss: 0.7739 - val_mse: 0.7739\n",
      "Epoch 20/100\n",
      "878/878 [==============================] - 1s 915us/step - loss: 0.8329 - mse: 0.8329 - val_loss: 0.8211 - val_mse: 0.8211\n",
      "Epoch 21/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7881 - mse: 0.7881 - val_loss: 0.7376 - val_mse: 0.7376\n",
      "Epoch 22/100\n",
      "878/878 [==============================] - 1s 983us/step - loss: 0.8316 - mse: 0.8316 - val_loss: 0.7270 - val_mse: 0.7270\n",
      "Epoch 23/100\n",
      "878/878 [==============================] - 1s 992us/step - loss: 0.7973 - mse: 0.7973 - val_loss: 0.7623 - val_mse: 0.7623\n",
      "Epoch 24/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.8214 - mse: 0.8214 - val_loss: 0.7192 - val_mse: 0.7192\n",
      "Epoch 25/100\n",
      "878/878 [==============================] - 1s 990us/step - loss: 0.7709 - mse: 0.7709 - val_loss: 0.7161 - val_mse: 0.7161\n",
      "Epoch 26/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7727 - mse: 0.7727 - val_loss: 0.7510 - val_mse: 0.7510\n",
      "Epoch 27/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7459 - mse: 0.7459 - val_loss: 0.9655 - val_mse: 0.9655\n",
      "Epoch 28/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.8026 - mse: 0.8026 - val_loss: 0.7250 - val_mse: 0.7250\n",
      "Epoch 29/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7645 - mse: 0.7645 - val_loss: 0.7121 - val_mse: 0.7121\n",
      "Epoch 30/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7411 - mse: 0.7411 - val_loss: 0.7230 - val_mse: 0.7230\n",
      "Epoch 31/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7812 - mse: 0.7812 - val_loss: 0.6996 - val_mse: 0.6996\n",
      "Epoch 32/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7822 - mse: 0.7822 - val_loss: 0.7459 - val_mse: 0.7459\n",
      "Epoch 33/100\n",
      "878/878 [==============================] - 1s 965us/step - loss: 0.7847 - mse: 0.7847 - val_loss: 0.7296 - val_mse: 0.7296\n",
      "Epoch 34/100\n",
      "878/878 [==============================] - 1s 966us/step - loss: 0.7601 - mse: 0.7601 - val_loss: 0.6977 - val_mse: 0.6977\n",
      "Epoch 35/100\n",
      "878/878 [==============================] - 1s 993us/step - loss: 0.7355 - mse: 0.7355 - val_loss: 0.6826 - val_mse: 0.6826\n",
      "Epoch 36/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7605 - mse: 0.7605 - val_loss: 0.7020 - val_mse: 0.7020\n",
      "Epoch 37/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7445 - mse: 0.7445 - val_loss: 0.6936 - val_mse: 0.6936\n",
      "Epoch 38/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7287 - mse: 0.7287 - val_loss: 0.7076 - val_mse: 0.7076\n",
      "Epoch 39/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7152 - mse: 0.7152 - val_loss: 0.6765 - val_mse: 0.6765\n",
      "Epoch 40/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7799 - mse: 0.7799 - val_loss: 0.7288 - val_mse: 0.7288\n",
      "Epoch 41/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7186 - mse: 0.7186 - val_loss: 0.6764 - val_mse: 0.6764\n",
      "Epoch 42/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7575 - mse: 0.7575 - val_loss: 0.6889 - val_mse: 0.6889\n",
      "Epoch 43/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7275 - mse: 0.7275 - val_loss: 0.6609 - val_mse: 0.6609\n",
      "Epoch 44/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7390 - mse: 0.7390 - val_loss: 0.6575 - val_mse: 0.6575\n",
      "Epoch 45/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7345 - mse: 0.7345 - val_loss: 0.7529 - val_mse: 0.7529\n",
      "Epoch 46/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7233 - mse: 0.7233 - val_loss: 0.6737 - val_mse: 0.6737\n",
      "Epoch 47/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7110 - mse: 0.7110 - val_loss: 0.6613 - val_mse: 0.6613\n",
      "Epoch 48/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7286 - mse: 0.7286 - val_loss: 0.7549 - val_mse: 0.7549\n",
      "Epoch 49/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7362 - mse: 0.7362 - val_loss: 0.7107 - val_mse: 0.7107\n",
      "Epoch 50/100\n",
      "878/878 [==============================] - 1s 979us/step - loss: 0.6835 - mse: 0.6835 - val_loss: 0.6838 - val_mse: 0.6838\n",
      "Epoch 51/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6907 - mse: 0.6907 - val_loss: 0.7809 - val_mse: 0.7809\n",
      "Epoch 52/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6843 - mse: 0.6843 - val_loss: 0.6778 - val_mse: 0.6778\n",
      "Epoch 53/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7091 - mse: 0.7091 - val_loss: 0.6490 - val_mse: 0.6490\n",
      "Epoch 54/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6844 - mse: 0.6844 - val_loss: 0.6514 - val_mse: 0.6514\n",
      "Epoch 55/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6878 - mse: 0.6878 - val_loss: 0.6473 - val_mse: 0.6473\n",
      "Epoch 56/100\n",
      "878/878 [==============================] - 1s 982us/step - loss: 0.7444 - mse: 0.7444 - val_loss: 0.6400 - val_mse: 0.6400\n",
      "Epoch 57/100\n",
      "878/878 [==============================] - 1s 915us/step - loss: 0.7148 - mse: 0.7148 - val_loss: 0.8401 - val_mse: 0.8401\n",
      "Epoch 58/100\n",
      "878/878 [==============================] - 1s 949us/step - loss: 0.7370 - mse: 0.7370 - val_loss: 0.8137 - val_mse: 0.8137\n",
      "Epoch 59/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7080 - mse: 0.7080 - val_loss: 0.9009 - val_mse: 0.9009\n",
      "Epoch 60/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7156 - mse: 0.7156 - val_loss: 0.6352 - val_mse: 0.6352\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6980 - mse: 0.6980 - val_loss: 0.7869 - val_mse: 0.7869\n",
      "Epoch 62/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.7172 - mse: 0.7172 - val_loss: 0.8138 - val_mse: 0.8138\n",
      "Epoch 63/100\n",
      "878/878 [==============================] - 1s 969us/step - loss: 0.6939 - mse: 0.6939 - val_loss: 0.6189 - val_mse: 0.6189\n",
      "Epoch 64/100\n",
      "878/878 [==============================] - 1s 988us/step - loss: 0.6966 - mse: 0.6966 - val_loss: 0.8766 - val_mse: 0.8766\n",
      "Epoch 65/100\n",
      "878/878 [==============================] - 1s 964us/step - loss: 0.6897 - mse: 0.6897 - val_loss: 0.8144 - val_mse: 0.8144\n",
      "Epoch 66/100\n",
      "878/878 [==============================] - 1s 900us/step - loss: 0.6672 - mse: 0.6672 - val_loss: 0.6422 - val_mse: 0.6422\n",
      "Epoch 67/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6867 - mse: 0.6867 - val_loss: 0.6132 - val_mse: 0.6132\n",
      "Epoch 68/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6844 - mse: 0.6844 - val_loss: 0.6894 - val_mse: 0.6894\n",
      "Epoch 69/100\n",
      "878/878 [==============================] - 1s 957us/step - loss: 0.7342 - mse: 0.7342 - val_loss: 0.6311 - val_mse: 0.6311\n",
      "Epoch 70/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6923 - mse: 0.6923 - val_loss: 0.9880 - val_mse: 0.9880\n",
      "Epoch 71/100\n",
      "878/878 [==============================] - 1s 1000us/step - loss: 0.7000 - mse: 0.7000 - val_loss: 0.6042 - val_mse: 0.6042\n",
      "Epoch 72/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6651 - mse: 0.6651 - val_loss: 0.5967 - val_mse: 0.5967\n",
      "Epoch 73/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6968 - mse: 0.6968 - val_loss: 0.6011 - val_mse: 0.6011\n",
      "Epoch 74/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6647 - mse: 0.6647 - val_loss: 0.6138 - val_mse: 0.6138\n",
      "Epoch 75/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6347 - mse: 0.6347 - val_loss: 0.5907 - val_mse: 0.5907\n",
      "Epoch 76/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6743 - mse: 0.6743 - val_loss: 0.6255 - val_mse: 0.6255\n",
      "Epoch 77/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6422 - mse: 0.6422 - val_loss: 0.5891 - val_mse: 0.5891 - loss: 0.6413 - mse: 0.641\n",
      "Epoch 78/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6631 - mse: 0.6631 - val_loss: 0.5935 - val_mse: 0.5935\n",
      "Epoch 79/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6750 - mse: 0.6750 - val_loss: 0.8395 - val_mse: 0.8395\n",
      "Epoch 80/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6724 - mse: 0.6724 - val_loss: 0.5861 - val_mse: 0.5861\n",
      "Epoch 81/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6616 - mse: 0.6616 - val_loss: 0.7648 - val_mse: 0.7648\n",
      "Epoch 82/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6674 - mse: 0.6674 - val_loss: 0.6198 - val_mse: 0.6198\n",
      "Epoch 83/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6598 - mse: 0.6598 - val_loss: 1.0171 - val_mse: 1.0171\n",
      "Epoch 84/100\n",
      "878/878 [==============================] - 1s 981us/step - loss: 0.6843 - mse: 0.6843 - val_loss: 0.6474 - val_mse: 0.6474\n",
      "Epoch 85/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6581 - mse: 0.6581 - val_loss: 0.5949 - val_mse: 0.5949\n",
      "Epoch 86/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6593 - mse: 0.6593 - val_loss: 0.6067 - val_mse: 0.6067\n",
      "Epoch 87/100\n",
      "878/878 [==============================] - 1s 968us/step - loss: 0.6636 - mse: 0.6636 - val_loss: 0.5961 - val_mse: 0.5961\n",
      "Epoch 88/100\n",
      "878/878 [==============================] - 1s 991us/step - loss: 0.6603 - mse: 0.6603 - val_loss: 0.6136 - val_mse: 0.6136\n",
      "Epoch 89/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6672 - mse: 0.6672 - val_loss: 0.7548 - val_mse: 0.7548\n",
      "Epoch 90/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6591 - mse: 0.6591 - val_loss: 0.5963 - val_mse: 0.5963\n",
      "Epoch 91/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6411 - mse: 0.6411 - val_loss: 0.5842 - val_mse: 0.5842\n",
      "Epoch 92/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6619 - mse: 0.6619 - val_loss: 0.5773 - val_mse: 0.5773\n",
      "Epoch 93/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6619 - mse: 0.6619 - val_loss: 0.5736 - val_mse: 0.5736\n",
      "Epoch 94/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6226 - mse: 0.6226 - val_loss: 0.5678 - val_mse: 0.5678\n",
      "Epoch 95/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6527 - mse: 0.6527 - val_loss: 0.5892 - val_mse: 0.5892\n",
      "Epoch 96/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6723 - mse: 0.6723 - val_loss: 0.5712 - val_mse: 0.5712\n",
      "Epoch 97/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6108 - mse: 0.6108 - val_loss: 0.5797 - val_mse: 0.5797\n",
      "Epoch 98/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6509 - mse: 0.6509 - val_loss: 0.7956 - val_mse: 0.7956\n",
      "Epoch 99/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6407 - mse: 0.6407 - val_loss: 0.6212 - val_mse: 0.6212\n",
      "Epoch 100/100\n",
      "878/878 [==============================] - 1s 1ms/step - loss: 0.6766 - mse: 0.6766 - val_loss: 0.5829 - val_mse: 0.5829\n"
     ]
    }
   ],
   "source": [
    "hist_1 = model1.fit(np.array(x_train),np.array(y_train),\n",
    "          batch_size=12, epochs=100,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 0s 1ms/step - loss: 0.5829 - mse: 0.5829\n",
      "mse: 58.29%\n"
     ]
    }
   ],
   "source": [
    "scores = model1.evaluate(x_test, y_test)\n",
    "print(\"%s: %.2f%%\" % (model1.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
